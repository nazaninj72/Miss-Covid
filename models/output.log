Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/nazaninjafar/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/nazaninjafar/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/nazaninjafar/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/nazaninjafar/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/nazaninjafar/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/nazaninjafar/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/nazaninjafar/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/nazaninjafar/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/nazaninjafar/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/nazaninjafar/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/nazaninjafar/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

Starting new HTTPS connection (1): cdn.huggingface.co:443
https://cdn.huggingface.co:443 "HEAD /bert-base-uncased-pytorch_model.bin HTTP/1.1" 200 0
loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/nazaninjafar/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
All model checkpoint weights were used when initializing BertModel.

All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertModel for predictions without further training.
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/nazaninjafar/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/nazaninjafar/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/nazaninjafar/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

Starting new HTTPS connection (1): cdn.huggingface.co:443
https://cdn.huggingface.co:443 "HEAD /bert-base-uncased-pytorch_model.bin HTTP/1.1" 200 0
loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/nazaninjafar/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
All model checkpoint weights were used when initializing BertModel.

All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertModel for predictions without further training.
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/nazaninjafar/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/nazaninjafar/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/nazaninjafar/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

Starting new HTTPS connection (1): cdn.huggingface.co:443
https://cdn.huggingface.co:443 "HEAD /bert-base-uncased-pytorch_model.bin HTTP/1.1" 200 0
loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/nazaninjafar/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
All model checkpoint weights were used when initializing BertModel.

All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertModel for predictions without further training.
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/nazaninjafar/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/nazaninjafar/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/nazaninjafar/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

Starting new HTTPS connection (1): cdn.huggingface.co:443
https://cdn.huggingface.co:443 "HEAD /bert-base-uncased-pytorch_model.bin HTTP/1.1" 200 0
loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/nazaninjafar/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
All model checkpoint weights were used when initializing BertModel.

All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertModel for predictions without further training.
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/nazaninjafar/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/nazaninjafar/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/nazaninjafar/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

Starting new HTTPS connection (1): cdn.huggingface.co:443
https://cdn.huggingface.co:443 "HEAD /bert-base-uncased-pytorch_model.bin HTTP/1.1" 200 0
loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/nazaninjafar/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
All model checkpoint weights were used when initializing BertModel.

All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertModel for predictions without further training.
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/nazaninjafar/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/nazaninjafar/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/nazaninjafar/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

Starting new HTTPS connection (1): cdn.huggingface.co:443
https://cdn.huggingface.co:443 "HEAD /bert-base-uncased-pytorch_model.bin HTTP/1.1" 200 0
loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/nazaninjafar/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
All model checkpoint weights were used when initializing BertModel.

All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertModel for predictions without further training.
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/nazaninjafar/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/nazaninjafar/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/nazaninjafar/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

Starting new HTTPS connection (1): cdn.huggingface.co:443
https://cdn.huggingface.co:443 "HEAD /bert-base-uncased-pytorch_model.bin HTTP/1.1" 200 0
loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/nazaninjafar/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
All model checkpoint weights were used when initializing BertModel.

All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertModel for predictions without further training.
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/config.json from cache at /home/nazaninjafar/.cache/torch/transformers/7fe0c0c31e05dc4ee4352acd3d2f55769729af6112ef726b17d110728bd89b31.94acc9b2980ce55713e34d393e99698aa32bc14cfb1143c33dd4a0605b374b89
Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

Model name 'digitalepidemiologylab/covid-twitter-bert' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'digitalepidemiologylab/covid-twitter-bert' is a path, a model identifier, or url to a directory containing tokenizer files.
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/vocab.txt HTTP/1.1" 200 0
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/added_tokens.json HTTP/1.1" 404 0
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/special_tokens_map.json HTTP/1.1" 404 0
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/tokenizer_config.json HTTP/1.1" 404 0
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/tokenizer.json HTTP/1.1" 404 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/vocab.txt from cache at /home/nazaninjafar/.cache/torch/transformers/b042b84bc66b83a767b8b3bb612da63e36440e54a3fee7f7e3dba9a90b3ff919.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/added_tokens.json from cache at None
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/special_tokens_map.json from cache at None
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/tokenizer_config.json from cache at None
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/tokenizer.json from cache at None
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/config.json from cache at /home/nazaninjafar/.cache/torch/transformers/7fe0c0c31e05dc4ee4352acd3d2f55769729af6112ef726b17d110728bd89b31.94acc9b2980ce55713e34d393e99698aa32bc14cfb1143c33dd4a0605b374b89
Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

Model name 'digitalepidemiologylab/covid-twitter-bert' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'digitalepidemiologylab/covid-twitter-bert' is a path, a model identifier, or url to a directory containing tokenizer files.
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/vocab.txt HTTP/1.1" 200 0
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/added_tokens.json HTTP/1.1" 404 0
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/special_tokens_map.json HTTP/1.1" 404 0
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/tokenizer_config.json HTTP/1.1" 404 0
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/tokenizer.json HTTP/1.1" 404 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/vocab.txt from cache at /home/nazaninjafar/.cache/torch/transformers/b042b84bc66b83a767b8b3bb612da63e36440e54a3fee7f7e3dba9a90b3ff919.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/added_tokens.json from cache at None
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/special_tokens_map.json from cache at None
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/tokenizer_config.json from cache at None
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/tokenizer.json from cache at None
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/config.json from cache at /home/nazaninjafar/.cache/torch/transformers/7fe0c0c31e05dc4ee4352acd3d2f55769729af6112ef726b17d110728bd89b31.94acc9b2980ce55713e34d393e99698aa32bc14cfb1143c33dd4a0605b374b89
Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

Starting new HTTPS connection (1): cdn.huggingface.co:443
https://cdn.huggingface.co:443 "HEAD /digitalepidemiologylab/covid-twitter-bert/pytorch_model.bin HTTP/1.1" 200 0
loading weights file https://cdn.huggingface.co/digitalepidemiologylab/covid-twitter-bert/pytorch_model.bin from cache at /home/nazaninjafar/.cache/torch/transformers/762d5eb2eaea1a93f664af70b2e0bfad30b9544e84a058f118b0a4b5afba4c86.919a2ebf5a0c29d820f3c25a71334552e9557db0fb2f3b856e7e7a8479ceb7b0
All model checkpoint weights were used when initializing BertModel.

All the weights of BertModel were initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertModel for predictions without further training.
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/config.json from cache at /home/nazaninjafar/.cache/torch/transformers/7fe0c0c31e05dc4ee4352acd3d2f55769729af6112ef726b17d110728bd89b31.94acc9b2980ce55713e34d393e99698aa32bc14cfb1143c33dd4a0605b374b89
Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

Model name 'digitalepidemiologylab/covid-twitter-bert' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'digitalepidemiologylab/covid-twitter-bert' is a path, a model identifier, or url to a directory containing tokenizer files.
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/vocab.txt HTTP/1.1" 200 0
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/added_tokens.json HTTP/1.1" 404 0
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/special_tokens_map.json HTTP/1.1" 404 0
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/tokenizer_config.json HTTP/1.1" 404 0
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/tokenizer.json HTTP/1.1" 404 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/vocab.txt from cache at /home/nazaninjafar/.cache/torch/transformers/b042b84bc66b83a767b8b3bb612da63e36440e54a3fee7f7e3dba9a90b3ff919.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/added_tokens.json from cache at None
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/special_tokens_map.json from cache at None
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/tokenizer_config.json from cache at None
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/tokenizer.json from cache at None
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/config.json from cache at /home/nazaninjafar/.cache/torch/transformers/7fe0c0c31e05dc4ee4352acd3d2f55769729af6112ef726b17d110728bd89b31.94acc9b2980ce55713e34d393e99698aa32bc14cfb1143c33dd4a0605b374b89
Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

Model name 'digitalepidemiologylab/covid-twitter-bert' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'digitalepidemiologylab/covid-twitter-bert' is a path, a model identifier, or url to a directory containing tokenizer files.
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/vocab.txt HTTP/1.1" 200 0
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/added_tokens.json HTTP/1.1" 404 0
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/special_tokens_map.json HTTP/1.1" 404 0
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/tokenizer_config.json HTTP/1.1" 404 0
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/tokenizer.json HTTP/1.1" 404 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/vocab.txt from cache at /home/nazaninjafar/.cache/torch/transformers/b042b84bc66b83a767b8b3bb612da63e36440e54a3fee7f7e3dba9a90b3ff919.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/added_tokens.json from cache at None
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/special_tokens_map.json from cache at None
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/tokenizer_config.json from cache at None
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/tokenizer.json from cache at None
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/config.json from cache at /home/nazaninjafar/.cache/torch/transformers/7fe0c0c31e05dc4ee4352acd3d2f55769729af6112ef726b17d110728bd89b31.94acc9b2980ce55713e34d393e99698aa32bc14cfb1143c33dd4a0605b374b89
Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

Starting new HTTPS connection (1): cdn.huggingface.co:443
https://cdn.huggingface.co:443 "HEAD /digitalepidemiologylab/covid-twitter-bert/pytorch_model.bin HTTP/1.1" 200 0
loading weights file https://cdn.huggingface.co/digitalepidemiologylab/covid-twitter-bert/pytorch_model.bin from cache at /home/nazaninjafar/.cache/torch/transformers/762d5eb2eaea1a93f664af70b2e0bfad30b9544e84a058f118b0a4b5afba4c86.919a2ebf5a0c29d820f3c25a71334552e9557db0fb2f3b856e7e7a8479ceb7b0
All model checkpoint weights were used when initializing BertModel.

All the weights of BertModel were initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertModel for predictions without further training.
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/config.json from cache at /home/nazaninjafar/.cache/torch/transformers/7fe0c0c31e05dc4ee4352acd3d2f55769729af6112ef726b17d110728bd89b31.94acc9b2980ce55713e34d393e99698aa32bc14cfb1143c33dd4a0605b374b89
Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

Model name 'digitalepidemiologylab/covid-twitter-bert' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'digitalepidemiologylab/covid-twitter-bert' is a path, a model identifier, or url to a directory containing tokenizer files.
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/vocab.txt HTTP/1.1" 200 0
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/added_tokens.json HTTP/1.1" 404 0
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/special_tokens_map.json HTTP/1.1" 404 0
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/tokenizer_config.json HTTP/1.1" 404 0
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/tokenizer.json HTTP/1.1" 404 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/vocab.txt from cache at /home/nazaninjafar/.cache/torch/transformers/b042b84bc66b83a767b8b3bb612da63e36440e54a3fee7f7e3dba9a90b3ff919.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/added_tokens.json from cache at None
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/special_tokens_map.json from cache at None
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/tokenizer_config.json from cache at None
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/tokenizer.json from cache at None
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/config.json from cache at /home/nazaninjafar/.cache/torch/transformers/7fe0c0c31e05dc4ee4352acd3d2f55769729af6112ef726b17d110728bd89b31.94acc9b2980ce55713e34d393e99698aa32bc14cfb1143c33dd4a0605b374b89
Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

Model name 'digitalepidemiologylab/covid-twitter-bert' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'digitalepidemiologylab/covid-twitter-bert' is a path, a model identifier, or url to a directory containing tokenizer files.
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/vocab.txt HTTP/1.1" 200 0
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/added_tokens.json HTTP/1.1" 404 0
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/special_tokens_map.json HTTP/1.1" 404 0
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/tokenizer_config.json HTTP/1.1" 404 0
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/tokenizer.json HTTP/1.1" 404 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/vocab.txt from cache at /home/nazaninjafar/.cache/torch/transformers/b042b84bc66b83a767b8b3bb612da63e36440e54a3fee7f7e3dba9a90b3ff919.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/added_tokens.json from cache at None
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/special_tokens_map.json from cache at None
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/tokenizer_config.json from cache at None
loading file https://s3.amazonaws.com/models.huggingface.co/bert/digitalepidemiologylab/covid-twitter-bert/tokenizer.json from cache at None
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/nazaninjafar/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

Starting new HTTPS connection (1): cdn.huggingface.co:443
https://cdn.huggingface.co:443 "HEAD /bert-base-uncased-pytorch_model.bin HTTP/1.1" 200 0
loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/nazaninjafar/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
All model checkpoint weights were used when initializing BertModel.

All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertModel for predictions without further training.
