{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "Device name: GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11523260416"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_properties(device).total_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    \"\"\"\n",
    "    - Remove entity mentions (eg. '@united')\n",
    "    - Correct errors (eg. '&amp;' to '&')\n",
    "    @param    text (str): a string to be processed.\n",
    "    @return   text (Str): the processed string.\n",
    "    \"\"\"\n",
    "    # Remove '@name'\n",
    "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    # Replace '&amp;' with '&'\n",
    "    text = re.sub(r'&amp;', '&', text)\n",
    "\n",
    "    # Remove trailing whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text=text.replace(\"#\",\"\")\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Load data and set labels\n",
    "\n",
    "data = pd.read_csv('/home/nazaninjafar/ds4cg2020/bert-covid/data/alldata2.tsv')\n",
    "# data=data.append(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.tweet.values\n",
    "y = data.label.values\n",
    "\n",
    "X_train, X_val, y_train, y_val =\\\n",
    "    train_test_split(X, y,stratify = y, test_size=0.1, random_state=42)\n",
    "# train_idx, test_idx, y_train, y_test= train_test_split(indices, y,stratify = y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  nhl teams can't control the seasonal flu that runs through their dressing rooms every season, and now they think they can control the coronavirus? #nhl #covid19\n",
      "Processed:  nhl teams can't control the seasonal flu that runs through their dressing rooms every season, and now they think they can control the coronavirus? nhl covid19\n"
     ]
    }
   ],
   "source": [
    "# Print sentence 0\n",
    "print('Original: ', X[0])\n",
    "print('Processed: ', text_preprocessing(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "# Create a function to tokenize a set of texts\n",
    "def preprocessing_for_ctbert(data):\n",
    "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
    "    @param    data (np.array): Array of texts to be processed.\n",
    "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
    "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
    "                  tokens should be attended to by the model.\n",
    "    \"\"\"\n",
    "    # Create empty lists to store outputs\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in data:\n",
    "        # `encode_plus` will:\n",
    "        #    (1) Tokenize the sentence\n",
    "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
    "        #    (3) Truncate/Pad sentence to max length\n",
    "        #    (4) Map tokens to their IDs\n",
    "        #    (5) Create attention mask\n",
    "        #    (6) Return a dictionary of outputs\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text=text_preprocessing(sent),  # Preprocess sentence\n",
    "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
    "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
    "            pad_to_max_length=True,         # Pad sentence to max length\n",
    "            #return_tensors='pt',           # Return PyTorch tensor\n",
    "            return_attention_mask=True,     # Return attention mask\n",
    "            truncation=True\n",
    "            )\n",
    "        \n",
    "        # Add the outputs to the lists\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length:  317\n"
     ]
    }
   ],
   "source": [
    "# Encode our concatenated data\n",
    "encoded_tweets = [tokenizer.encode(sent, add_special_tokens=True) for sent in X]\n",
    "\n",
    "# Find the maximum length\n",
    "max_len = max([len(sent) for sent in encoded_tweets])\n",
    "print('Max length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  nhl teams can't control the seasonal flu that runs through their dressing rooms every season, and now they think they can control the coronavirus? #nhl #covid19\n",
      "Token IDs:  [101, 7097, 2780, 2064, 1005, 1056, 2491, 1996, 12348, 19857, 2008, 3216, 2083, 2037, 11225, 4734, 2296, 2161, 1010, 1998, 2085, 2027, 2228, 2027, 2064, 2491, 1996, 21887, 23350, 1029, 7097, 2522, 17258, 16147, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Tokenizing data...\n"
     ]
    }
   ],
   "source": [
    "# Specify `MAX_LEN`\n",
    "MAX_LEN = 160\n",
    "\n",
    "# Print sentence 0 and its encoded token ids\n",
    "token_ids = list(preprocessing_for_ctbert([X[0]])[0].squeeze().numpy())\n",
    "print('Original: ', X[0])\n",
    "print('Token IDs: ', token_ids)\n",
    "\n",
    "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
    "print('Tokenizing data...')\n",
    "train_inputs, train_masks = preprocessing_for_ctbert(X_train)\n",
    "val_inputs, val_masks = preprocessing_for_ctbert(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2115, 19857,  ...,     0,     0,     0],\n",
       "        [  101, 15624,  1010,  ...,     0,     0,     0],\n",
       "        [  101,  2079,  2017,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101, 10090,  4615,  ...,     0,     0,     0],\n",
       "        [  101, 21887, 23350,  ...,     0,     0,     0],\n",
       "        [  101,  2151, 16270,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Convert other data types to torch.Tensor\n",
    "train_labels = torch.tensor(y_train)\n",
    "val_labels = torch.tensor(y_val)\n",
    "\n",
    "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# import torch\n",
    "import torch.nn as nn\n",
    "# model = AutoModel.from_pretrained(\"digitalepidemiologylab/covid-twitter-bert\")\n",
    "\n",
    "# Create the BertClassfier class\n",
    "class BertClassifier(nn.Module):\n",
    "    \"\"\"Bert Model for Classification Tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self, freeze_bert=False):\n",
    "        \"\"\"\n",
    "        @param    bert: a BertModel object\n",
    "        @param    classifier: a torch.nn.Module classifier\n",
    "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
    "        \"\"\"\n",
    "        super(BertClassifier, self).__init__()\n",
    "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
    "        D_in, H, D_out = 768, 50, 2\n",
    "\n",
    "        # Instantiate BERT model\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        # Instantiate an one-layer feed-forward classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(D_in, H),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "\n",
    "        # Freeze the BERT model\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Feed input to BERT and the classifier to compute logits.\n",
    "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
    "                      max_length)\n",
    "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
    "                      information with shape (batch_size, max_length)\n",
    "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
    "                      num_labels)\n",
    "        \"\"\"\n",
    "#         print(\"input_ids\",input_ids.size())\n",
    "#         print(\"attention_mask\",attention_mask.size())\n",
    "        # Feed input to BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "\n",
    "        # Feed input to classifier to compute logits\n",
    "        logits = self.classifier(last_hidden_state_cls)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningrate=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "def initialize_model(epochs=4,lr=learningrate):\n",
    "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
    "    \"\"\"\n",
    "    # Instantiate Bert Classifier\n",
    "    bert_classifier = BertClassifier(freeze_bert=False)\n",
    "\n",
    "    # Tell PyTorch to run the model on GPU\n",
    "    bert_classifier.to(device)\n",
    "\n",
    "    # Create the optimizer\n",
    "    optimizer = AdamW(bert_classifier.parameters(),\n",
    "                      lr=learningrate,    # Default learning rate\n",
    "                      eps=1e-8    # Default epsilon value\n",
    "                      )\n",
    "\n",
    "    # Total number of training steps\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    # Set up the learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=0, # Default value\n",
    "                                                num_training_steps=total_steps)\n",
    "    return bert_classifier, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import torch.nn as nn\n",
    "# Specify loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
    "    \"\"\"Train the BertClassifier model.\n",
    "    \"\"\"\n",
    "    # Start training loop\n",
    "    print(\"Start training...\\n\")\n",
    "    for epoch_i in range(epochs):\n",
    "        # =======================================\n",
    "        #               Training\n",
    "        # =======================================\n",
    "        # Print the header of the result table\n",
    "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} |{'Train Acc':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "        print(\"-\"*70)\n",
    "\n",
    "        # Measure the elapsed time of each epoch\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "        # Reset tracking variables at the beginning of each epoch\n",
    "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "\n",
    "        # Put the model into the training mode\n",
    "        model.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch_counts +=1\n",
    "            # Load batch to GPU\n",
    "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Zero out any previously calculated gradients\n",
    "            model.zero_grad()\n",
    "#             print('b_input_ids',b_input_ids.size())\n",
    "#             print('b_attn_mask',b_attn_mask.size())\n",
    "            # Perform a forward pass. This will return logits.\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "            # Compute loss and accumulate the loss values\n",
    "            loss = loss_fn(logits, b_labels)\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Update parameters and the learning rate\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Print the loss values and time elapsed for every 20 batches\n",
    "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
    "                # Calculate time elapsed for 20 batches\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "\n",
    "                # Print training results\n",
    "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "                # Reset batch tracking variables\n",
    "                batch_loss, batch_counts = 0, 0\n",
    "                t0_batch = time.time()\n",
    "\n",
    "        # Calculate the average loss over the entire training data\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        print(\"-\"*70)\n",
    "        # =======================================\n",
    "        #               Evaluation\n",
    "        # =======================================\n",
    "        if evaluation == True:\n",
    "            # After the completion of each training epoch, measure the model's performance\n",
    "            # on our validation set.\n",
    "            val_loss, val_accuracy,_ = evaluate(model, val_dataloader)\n",
    "            _,train_accuracy,_=evaluate(model,train_dataloader)\n",
    "            # Print performance over the entire training data\n",
    "            time_elapsed = time.time() - t0_epoch\n",
    "            \n",
    "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {train_accuracy:^9.2f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "            print(\"-\"*70)\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "\n",
    "\n",
    "def evaluate(model, val_dataloader):\n",
    "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
    "    on our validation set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "    preds=[]\n",
    "    # For each batch in our validation set...\n",
    "    for batch in val_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(logits, b_labels)\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "        # Get the predictions\n",
    "        pred= torch.argmax(logits, dim=1).flatten()\n",
    "        preds.append(pred)\n",
    "        # Calculate the accuracy rate\n",
    "        accuracy = (pred == b_labels).cpu().numpy().mean() * 100\n",
    "        val_accuracy.append(accuracy)\n",
    "\n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "    return val_loss, val_accuracy,preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters:\n",
    "epochs=20\n",
    "learningrate=5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   12    |   0.676811   |     -      |     -     |   4.11   \n",
      "----------------------------------------------------------------------\n",
      "   1    |    -    |   0.676811   |   80.40   |  0.603732  |   71.27   |   5.55   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   12    |   0.527990   |     -      |     -     |   4.17   \n",
      "----------------------------------------------------------------------\n",
      "   2    |    -    |   0.527990   |   88.43   |  0.502703  |   79.09   |   5.61   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   3    |   12    |   0.302813   |     -      |     -     |   4.29   \n",
      "----------------------------------------------------------------------\n",
      "   3    |    -    |   0.302813   |   97.12   |  0.458941  |   82.09   |   5.76   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   4    |   12    |   0.154271   |     -      |     -     |   4.24   \n",
      "----------------------------------------------------------------------\n",
      "   4    |    -    |   0.154271   |   98.08   |  0.566424  |   78.25   |   5.70   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   5    |   12    |   0.094697   |     -      |     -     |   4.27   \n",
      "----------------------------------------------------------------------\n",
      "   5    |    -    |   0.094697   |   99.28   |  0.521870  |   85.94   |   5.74   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   6    |   12    |   0.090521   |     -      |     -     |   4.30   \n",
      "----------------------------------------------------------------------\n",
      "   6    |    -    |   0.090521   |   98.80   |  0.450675  |   87.50   |   5.77   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   7    |   12    |   0.064753   |     -      |     -     |   4.26   \n",
      "----------------------------------------------------------------------\n",
      "   7    |    -    |   0.064753   |   99.28   |  0.441034  |   88.34   |   5.73   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   8    |   12    |   0.047786   |     -      |     -     |   4.20   \n",
      "----------------------------------------------------------------------\n",
      "   8    |    -    |   0.047786   |   99.28   |  0.692000  |   82.81   |   5.66   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   9    |   12    |   0.024752   |     -      |     -     |   4.23   \n",
      "----------------------------------------------------------------------\n",
      "   9    |    -    |   0.024752   |   99.52   |  0.713303  |   84.50   |   5.70   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  10    |   12    |   0.042163   |     -      |     -     |   4.22   \n",
      "----------------------------------------------------------------------\n",
      "  10    |    -    |   0.042163   |   99.52   |  0.823230  |   79.81   |   5.70   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  11    |   12    |   0.030765   |     -      |     -     |   4.28   \n",
      "----------------------------------------------------------------------\n",
      "  11    |    -    |   0.030765   |   99.52   |  0.784581  |   79.81   |   5.76   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  12    |   12    |   0.027220   |     -      |     -     |   4.21   \n",
      "----------------------------------------------------------------------\n",
      "  12    |    -    |   0.027220   |   99.52   |  0.840395  |   78.25   |   5.69   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  13    |   12    |   0.022236   |     -      |     -     |   4.23   \n",
      "----------------------------------------------------------------------\n",
      "  13    |    -    |   0.022236   |   99.52   |  0.717637  |   79.81   |   5.71   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  14    |   12    |   0.018780   |     -      |     -     |   4.21   \n",
      "----------------------------------------------------------------------\n",
      "  14    |    -    |   0.018780   |   99.52   |  0.753111  |   79.81   |   5.68   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  15    |   12    |   0.029509   |     -      |     -     |   4.27   \n",
      "----------------------------------------------------------------------\n",
      "  15    |    -    |   0.029509   |   99.52   |  0.901754  |   78.25   |   5.75   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  16    |   12    |   0.015361   |     -      |     -     |   4.26   \n",
      "----------------------------------------------------------------------\n",
      "  16    |    -    |   0.015361   |   99.52   |  0.910461  |   78.25   |   5.74   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  17    |   12    |   0.014608   |     -      |     -     |   4.25   \n",
      "----------------------------------------------------------------------\n",
      "  17    |    -    |   0.014608   |   99.52   |  0.854326  |   78.25   |   5.73   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  18    |   12    |   0.014665   |     -      |     -     |   4.29   \n",
      "----------------------------------------------------------------------\n",
      "  18    |    -    |   0.014665   |   99.52   |  0.815243  |   78.25   |   5.77   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  19    |   12    |   0.013493   |     -      |     -     |   4.26   \n",
      "----------------------------------------------------------------------\n",
      "  19    |    -    |   0.013493   |   99.52   |  0.778355  |   78.25   |   5.73   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  20    |   12    |   0.012836   |     -      |     -     |   4.22   \n",
      "----------------------------------------------------------------------\n",
      "  20    |    -    |   0.012836   |   99.52   |  0.793617  |   78.25   |   5.70   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)    # Set seed for reproducibility\n",
    "ctbert_classifier, optimizer, scheduler = initialize_model(epochs,learningrate)\n",
    "train(ctbert_classifier, train_dataloader, val_dataloader, epochs, evaluation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def bert_predict(model, test_dataloader):\n",
    "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
    "    on the test set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    all_logits = []\n",
    "\n",
    "    # For each batch in our test set...\n",
    "    for batch in test_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "        all_logits.append(logits)\n",
    "    \n",
    "    # Concatenate logits from each batch\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "\n",
    "    # Apply softmax to calculate probabilities\n",
    "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "\n",
    "def evaluate_roc(probs, y_true):\n",
    "    \"\"\"\n",
    "    - Print AUC and accuracy on the test set\n",
    "    - Plot ROC\n",
    "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
    "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
    "    \"\"\"\n",
    "    preds = probs[:, 1]\n",
    "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f'AUC: {roc_auc:.4f}')\n",
    "       \n",
    "    # Get accuracy over the test set\n",
    "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "    \n",
    "    # Plot ROC AUC\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8800\n",
      "Accuracy: 75.56%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3debyWc/7H8dentKEsGYYWGgqV1jMttrInS4iksWQL2aUfw8wwpmEMYx1bxWQMNYSElEFJaN+0iBQtRBKKSsvn98f3Os7dcc597s45933d5z7v5+NxP859Lfd1fe7rnHN/7u/1va7P19wdERGR4lSJOwAREcluShQiIpKUEoWIiCSlRCEiIkkpUYiISFJKFCIikpQShWwTM5trZp3jjiNbmNlNZjY4pn0PMbMBcey7vJnZ78zs9VK+Vn+TaaZEUYGZ2admts7M1prZiuiDY8d07tPdm7n7uHTuI5+Z1TCzO8xsSfQ+Pzaz/mZmmdh/EfF0NrNlifPc/XZ3vyhN+zMzu8rM5pjZD2a2zMyeM7OD0rG/0jKzW83sP2XZhrs/7e7HprCvXyTHTP5NVlZKFBXfSe6+I9AKaA38PuZ4tpmZbVfMoueAo4CuQG3gHKAPcH8aYjAzy7b/h/uBq4GrgF2BJsAI4ITy3lGS30HaxblvSZG761FBH8CnwNEJ038HXk2Y7gC8B3wLzAI6JyzbFfgX8DmwGhiRsOxEYGb0uveAFoX3CewFrAN2TVjWGvgaqBZNXwDMj7Y/Btg7YV0HLgc+BhYX8d6OAtYDDQrNbw9sBvaLpscBdwCTge+BlwrFlOwYjAP+CrwbvZf9gPOjmNcAi4BLonV3iNbZAqyNHnsBtwL/idbZJ3pf5wFLomNxc8L+agFPRsdjPvB/wLJifreNo/fZLsnvfwjwEPBqFO8kYN+E5fcDS6PjMg04LGHZrcBw4D/R8ouAdsD70bH6AvgnUD3hNc2A/wHfAF8CNwFdgJ+AjdExmRWtuxPweLSd5cAAoGq0rHd0zO8FVkXLegMTouUWLfsqiu0DoDnhS8LGaH9rgZcL/x8AVaO4PomOyTQK/Q3pUYrPmrgD0KMMv7yt/0HqR/9Q90fT9aJ/wq6EluMx0fSvouWvAv8FdgGqAZ2i+a2jf9D20T/dedF+ahSxz7eAixPiuQt4NHreDVgIHAhsB/wBeC9hXY8+dHYFahXx3v4GvF3M+/6Mgg/wcdEHUXPCh/nzFHxwl3QMxhE+0JtFMVYjfFvfN/qw6gT8CLSJ1u9MoQ92ik4UgwhJoSWwATgw8T1Fx7w+MLvw9hK2eynwWQm//yHR+2kXxf80MCxh+dlA3WhZP2AFUDMh7o3AKdGxqQW0JSTW7aL3Mh+4Jlq/NuFDvx9QM5puX/gYJOz7ReCx6HeyOyGR5//OegObgCujfdVi60RxHOEDfufo93AgsGfCex6Q5P+gP+H/YP/otS2BunH/r1b0R+wB6FGGX174B1lL+ObkwJvAztGyG4CnCq0/hvDBvyfhm/EuRWzzEeAvheYtoCCRJP5TXgS8FT03wrfXw6Pp14ALE7ZRhfChu3c07cCRSd7b4MQPvULLJhJ9Uyd82P8tYVlTwjfOqsmOQcJrbyvhGI8Aro6edya1RFE/YflkoGf0fBFwXMKyiwpvL2HZzcDEEmIbAgxOmO4KfJhk/dVAy4S4x5ew/WuAF6PnZwEzilnv52MQTe9BSJC1EuadBYyNnvcGlhTaRm8KEsWRwEeEpFWliPecLFEsALql4/+tMj+y7ZysbLtT3L024UPsAGC3aP7ewBlm9m3+AziUkCQaAN+4++oitrc30K/Q6xoQTrMU9jzQ0cz2BA4nJJ93ErZzf8I2viEkk3oJr1+a5H19HcValD2j5UVt5zNCy2A3kh+DImMws+PNbKKZfROt35WCY5qqFQnPfwTyLzDYq9D+kr3/VRT//lPZF2Z2vZnNN7PvoveyE1u/l8LvvYmZvRJdGPE9cHvC+g0Ip3NSsTfhd/BFwnF/jNCyKHLfidz9LcJpr4eAr8xsoJnVSXHf2xKnpEiJIke4+9uEb1t3R7OWEr5N75zw2MHd/xYt29XMdi5iU0uBvxZ63fbuPrSIfa4GXgfOBHoRWgCesJ1LCm2nlru/l7iJJG/pDaC9mTVInGlm7QkfBm8lzE5cpyHhlMrXJRyDX8RgZjUIye9uYA933xkYRUhwJcWbii8Ip5yKiruwN4H6ZpZXmh2Z2WGEPpAehJbjzsB3FLwX+OX7eQT4EGjs7nUI5/rz118K/KaY3RXezlJCi2K3hONex92bJXnN1ht0f8Dd2xJaiE0Ip5RKfF20731LWEe2kRJFbrkPOMbMWhI6KU8ys+PMrKqZ1Ywu76zv7l8QTg09bGa7mFk1Mzs82sYg4FIzax9dCbSDmZ1gZrWL2eczwLnA6dHzfI8CvzezZgBmtpOZnZHqG3H3Nwgfls+bWbPoPXSI3tcj7v5xwupnm1lTM9seuA0Y7u6bkx2DYnZbHagBrAQ2mdnxQOIlm18Cdc1sp1TfRyHPEo7JLmZWD7iiuBWj9/cwMDSKuXoUf08zuzGFfdUm9AOsBLYzsz8BJX0rr03oPF5rZgcAlyUsewXY08yuiS5brh0lbQjHZZ/8q8aiv6/XgX+YWR0zq2Jm+5pZpxTixsx+G/39VQN+IFzUsCVhX8UlLAinLP9iZo2jv98WZlY3lf1K8ZQocoi7rwT+DfzJ3ZcSOpRvInxYLCV8K8v/nZ9D+Ob9IaHz+ppoG1OBiwlN/9WEDuneSXY7knCFzgp3n5UQy4vAncCw6DTGHOD4bXxL3YGxwGhCX8x/CFfSXFlovacIrakVhI7Wq6IYSjoGW3H3NdFrnyW8917R+8tf/iEwFFgUnVIp6nRcMrcBy4DFhBbTcMI37+JcRcEpmG8Jp1ROBV5OYV9jCMftI8LpuPUkP9UFcD3hPa8hfGH4b/6C6NgcA5xEOM4fA0dEi5+Lfq4ys+nR83MJiXce4VgOJ7VTaRAS2qDodZ8RTsPdFS17HGgaHf8RRbz2HsLv73VC0nuc0FkuZWAFZwpEKh4zG0foSI3l7uiyMLPLCB3dKX3TFomLWhQiGWJme5rZIdGpmP0Jl5q+GHdcIiVJW6IwsyfM7Cszm1PMcjOzB8xsoZnNNrM26YpFJEtUJ1z9s4bQGf8SoR9CJKul7dRT1Dm6Fvi3uzcvYnlXwrnmroSbu+539/aF1xMRkXilrUXh7uMJ184Xpxshibi7TwR2jq7HFxGRLBJnMa56bH0VxrJo3heFVzSzPoQ6L+ywww5tDzjggIwEKCJSFgsWwLp1UCvG66722PAZO276llm+6Wt3/1VptlEhqja6+0BgIEBeXp5PnTo15ohERErWuXP4OW5chnec36VgBo88Al99hd1662el3VycVz0tZ+s7U+tH80REpLSWL4du3eCZ6P7Xyy6DW24p0ybjTBQjgXOjq586AN9Fd3SKiMi2codBg6BpU3jjDVi7ttw2nbZTT2Y2lFCobjcLo4LdQigUhrs/Sqih05Vw5++PhHEARERkW33yCVx8MYwdC0ccERLGvuVX8ipticLdzyphef7ANSIiUhYffADTpsHAgXDRRaFvohxViM5sEREpZM4cmD4dzj0XTjkFFi2Cuumpf6gSHiIiFclPP8Gtt0KbNnDzzbB+fZifpiQBalFIzAYOLLg4QyTXzJwJrVqV4wYnTYILL4S5c+Hss+Hee6FmzXLcQdHUopBYPfNM+GcSyUWtWkGvXuW0seXL4bDD4Lvv4JVX4KmnYLdtHXyxdNSikNi1ahXDDUkiFcVHH0GTJlCvHvz3v3DUUVAn1ZFhy4daFCIi2ejbb6FPHzjgABg/Psw79dSMJwlQi0JEJPuMHBnuqF6xAvr3h9/+NtZwlChERLLJRRfB44/DQQfBSy9BXl7cESlRiIjELrGIX14e7L033HADVK8eb1wRJQoRkTgtXQqXXgo9e8I554TnWUad2SIicdiyJZQAb9YsXPa3YUPcERVLLQoRkUz7+OPQFzF+PBx9dLjztFGjuKMqlhKFiEimzZsHs2fDE09A797lXsSvvClRiIhkwqxZoQzBeeeFgYUWLYJddok7qpSoj0JEJJ02bIA//jFczfTHPxYU8asgSQKUKERE0uf996F1axgwIBR9mjEjI0X8yptOPYmIpMPy5dCpE/z61zBqFBx/fNwRlZpaFCIi5Wn+/PCzXj149tlQErwCJwlQohARKR+rV8MFF0DTpvDOO2HeKadA7drxxlUOdOpJyqSsAw+V+8AuInF48UXo2xdWroTf/z72In7lTS0KKZOyDjxUrgO7iMThggvgtNNCX8TkyXD77RWywzoZtSikzDTwkFQ6iUX8OnSAxo3h+uuhWrV440oTJQoRkW3x2WdwySWhKXzuuWFwoRynU08iIqnYsgUeegiaN4cJE2Djxrgjyhi1KERESrJgQSjiN2ECHHssPPYY7LNP3FFljBKFiEhJFiwI90MMGRJON2V5Eb/ypkQhIlKUGTPCJX3nnw8nnxyK+O28c9xRxUJ9FCIiidavh5tuCvdC3HprQRG/SpokQIlCRKTAu++G673vuCOcYpo5M+fuiSgNnXoSEYFQxO+II0KNpjFjQqe1AGpRiEhlN29e+FmvHjz/PHzwgZJEIUoUIlI5ffNNGIa0WbMwdjXASSfBjjvGGlY20qknEal8nn8eLr8cVq2Cm2+Gdu3ijiirKVGISOXSuzc8+SS0aQOjR6t8cQqUKEQk9yUW8Tv4YDjwQOjXD7bTR2Aq0tpHYWZdzGyBmS00sxuLWN7QzMaa2Qwzm21mXdMZj4hUQosXh87pf/87TPfpAzfcoCSxDdKWKMysKvAQcDzQFDjLzJoWWu0PwLPu3hroCTycrnhEpJLZvBkeeCAU8Zs4saBVIdssnSm1HbDQ3RcBmNkwoBswL2EdB+pEz3cCPk9jPFmjrKPCZRONUCdZaf58uPBCeP/9MF71o49Cw4ZxR1VhpfPUUz1gacL0smheoluBs81sGTAKuLKoDZlZHzObamZTV65cmY5YM6qso8JlE41QJ1lp4cJQyO+pp+DVV5Ukyijuk3RnAUPc/R9m1hF4ysyau/uWxJXcfSAwECAvLy8n2o8aFU6knE2bBrNmhaFJTzop9E3UqVPy66RE6WxRLAcaJEzXj+YluhB4FsDd3wdqArulMSYRyTXr1sGNN0L79vCXvxQU8VOSKDfpTBRTgMZm1sjMqhM6q0cWWmcJcBSAmR1ISBQV/9ySiGTG+PHQsiXceWe4P2LGDBXxS4O0nXpy901mdgUwBqgKPOHuc83sNmCqu48E+gGDzOxaQsd2b3ddmiAiKVi+HI46Cho0gDfeCM8lLdLaR+Huowid1Inz/pTwfB5wSDpjEJEc88EHcNBBoYjfiy+Giq877BB3VDlNRQFFpGL4+ms45xxo0aKgiN+JJypJZEDcVz2JiCTnDs89B1dcAatXwy23hI5ryRglChHJbuedF+6HyMuDN98Mp50ko5QoRCT7JBbx69QpnG665hrVZ4qJ+ihEJLssWgRHHw1DhoTpCy+E669XkoiREoWIZIfNm+G++8KppSlToIo+nrKFUrSIxG/evFB6Y9IkOOGEUMSvfv24o5KIEoWIxG/xYvjkk1Axs2fP0DchWUOJQkTiMWVKKKN88cWhFbFoEdSuHXdUUgSdBBSRzPrxx9A53aED3HFHQRE/JYmspUQhIpkzbly41PUf/wgtCRXxqxB06klEMmPZMjjmGNh7b3jrrVCjSSoEtShEJL1mzQo/69eHl16C2bOVJCoYJQoRSY+VK8M4ua1awdtvh3ldu8L228cbl2wznXoSkfLlDsOGwVVXwXffwZ//DB07xh2VlIEShYiUr3POgaefDhVeH38cmjWLOyIpo5QThZlt7+4/pjMYEamgtmwJN8mZhf6Htm1Di6Jq1bgjk3JQYh+FmR1sZvOAD6Pplmb2cNojE5GKYeHCMAzpv/4Vpi+8EK69Vkkih6TSmX0vcBywCsDdZwGHpzMoEakANm2Cu+8ORfxmzIDq1eOOSNIkpVNP7r7Utq69sjk94VQMAweGkjSlNXNmuBBEpMKaMwfOPx+mToVu3eDhh2GvveKOStIklRbFUjM7GHAzq2Zm1wPz0xxXVnvmmfBhX1qtWoWrBkUqrCVL4LPPwtVNL76oJJHjUmlRXArcD9QDlgOvA33TGVRF0KpVqEYgUmlMmhRunuvTJ9wPsWgR7Lhj3FFJBqTSotjf3X/n7nu4++7ufjZwYLoDE5Es8cMPcN114V6Iv/8dNmwI85UkKo1UEsWDKc4TkVzz1luhiN+998Kll8L06VCjRtxRSYYVe+rJzDoCBwO/MrPrEhbVAXTdm0iuW7YMjjsOGjUKJTgO18WOlVWyPorqwI7ROomF4r8HTk9nUCISoxkzoHXrUMTv5ZehUyeoVSvuqCRGxSYKd38beNvMhrj7ZxmMSUTi8OWX4W7qZ58NV2p06gRdusQdlWSBVK56+tHM7gKaAT+PMOLuR6YtKhHJHPdQm+nqq2HtWhgwAA4+OO6oJIuk0pn9NKF8RyPgz8CnwJQ0xiQimdSrVyjkt//+4Qahm2+GatXijkqySCotirru/riZXZ1wOkqJQqQiSyzid+yx4dLXyy9XfSYpUiotio3Rzy/M7AQzaw3smsaYRCSdPvooVHh94okwff75qvQqSaXSohhgZjsB/Qj3T9QBrklrVCJS/jZtgnvugVtugZo1dSWTpKzEROHur0RPvwOOADCzQ9IZlIiUs9mz4YILYNo0OPVUeOgh2HPPuKOSCiLZDXdVgR6EGk+j3X2OmZ0I3ATUAlpnJkQRKbNly2DpUnjuOejePfRNiKQoWR/F48BFQF3gATP7D3A38Hd3TylJmFkXM1tgZgvN7MZi1ulhZvPMbK6ZlaF4t4hs5b334NFHw/P8In6nn64kIdss2amnPKCFu28xs5rACmBfd1+VyoajFslDwDHAMmCKmY1093kJ6zQGfg8c4u6rzWz30r4REYmsXRsucX3wQdh339BZXaMG7LBD3JFJBZUsUfzk7lsA3H29mS1KNUlE2gEL3X0RgJkNA7oB8xLWuRh4yN1XR/v5apuiL4WyDjoEGnhIstjrr4cy4EuWhMtdb79dRfykzJIligPMbHb03IB9o2kD3N1blLDtesDShOllQPtC6zQBMLN3CYUGb3X30YU3ZGZ9gD4ADRs2LGG3yeUPOlSWD3oNPCRZaelSOOGE0IoYPx4OPTTuiCRHJEsUmRhzYjugMdAZqA+MN7OD3P3bxJXcfSAwECAvL8/LulMNOiQ5Zdo0aNsWGjSAUaPgsMPC5a8i5aTYzmx3/yzZI4VtLwcaJEzXj+YlWgaMdPeN7r4Y+IiQOESkJCtWwBlnQF5eKAMOcMwxShJS7lK5M7u0pgCNzayRmVUHegIjC60zgtCawMx2I5yKWpTGmEQqPnd48klo2jSUAb/9dhXxk7RK5c7sUnH3TWZ2BTCG0P/whLvPNbPbgKnuPjJadqyZzQM2A/23scNcpPLp2TOUAj/kEBg8GA44IO6IJMellCjMrBbQ0N0XbMvG3X0UMKrQvD8lPHfguughIsVJLOLXtWvoh+jbF6qk86SASFDiX5mZnQTMBEZH063MrPApJBFJlw8/DMOQPv54mD7vPLjiCiUJyZhU/tJuJdwT8S2Au88kjE0hIum0cWPof2jZEubNgx13jDsiqaRSOfW00d2/s61v+y/zJaoiksTMmeGO6pkzQ9mNBx+EX/867qikkkolUcw1s15A1ajkxlXAe+kNS6SSW7EiPJ5/Hk47Le5opJJL5dTTlYTxsjcAzxDKjWs8CpHyNmECPPxweN6lC3zyiZKEZIVUEsUB7n6zu/82evzB3denPTKRymLNmtA5fdhhcN99sGFDmL/99vHGJRJJJVH8w8zmm9lfzKx52iMSqUzGjIHmzUNL4uqrYfp0FfGTrFNionD3Iwgj260EHjOzD8zsD2mPTCTXLV0KJ54YWg4TJoTWhK5skiyU0oXY7r7C3R8ALiXcU/GnEl4iIkVxh8mTw/MGDeC112DGDJXgkKyWyg13B5rZrWb2AfAg4Yqn+mmPTCTXfPFFGIa0ffuCIn5HH60ifpL1Urk89gngv8Bx7v55muMRyT3uMGQIXHcdrF8Pd94Z6jSJVBAlJgp375iJQERyVo8eMHx4uKpp8GBo0iTuiES2SbGJwsyedfce0SmnxDuxUx3hTqTy2rw5FPCrUgVOOgmOPBIuuUT1maRCStaiuDr6eWImAhHJGfPnw4UXhhIcF18M554bd0QiZZJshLsvoqd9ixjdrm9mwhOpQDZuhAEDwli7CxbATjvFHZFIuUilHXxMEfOOL+9ARCq0GTPCkKR//COcempoVfToEXdUIuUiWR/FZYSWw2/MbHbCotrAu+kOTKRC+fJL+PprGDECunWLOxqRcpWsj+IZ4DXgDuDGhPlr3P2btEYlUhGMHw8ffACXXx6K+C1cCLVqxR2VSLlLdurJ3f1T4HJgTcIDM9s1/aGJZKnvvw/DkHbqBA88UFDET0lCclRJLYoTgWmEy2MTRy5y4DdpjKtYCxZA586lf/3MmaGvUaRURo0Kl7l+/nm4ge6221TET3JesYnC3U+MfmbVsKfr1pXt9a1aQa9e5ROLVDJLl4b+h/33DzfQtW8fd0QiGVHindlmdggw091/MLOzgTbAfe6+JO3RFaFWLRg3Lo49S6XkDpMmQYcOoYjf66+H8hvVq8cdmUjGpHJ57CPAj2bWEugHfAI8ldaoRLLB55/DKadAx44FRfyOOEJJQiqdVBLFJnd3oBvwT3d/iHCJrEhucg81mZo2DS2Iu+9WET+p1FKpHrvGzH4PnAMcZmZVgGrpDUskRqefDi+8EK5qGjwY9tsv7ohEYpVKi+JMYANwgbuvIIxFcVdaoxLJtM2bYcuW8PyUU+DRR+Gtt5QkRAALZ5VKWMlsD+C30eRkd/8qrVElUbt2nq9ZMzWu3UsumjMHLrooFPK7+OK4oxFJCzOb5u55pXltKiPc9QAmA2cAPYBJZnZ6aXYmklV++gn+/Gdo0wY++QR22SXuiESyUip9FDcDv81vRZjZr4A3gOHpDEwkraZNg969Q2uiVy+47z741a/ijkokK6WSKKoUOtW0itT6NkSy16pV8O238PLLcKKGXBFJJpVEMdrMxgBDo+kzgVHpC0kkTcaODUX8rroKjj0WPv4YataMOyqRrFdiy8Dd+wOPAS2ix0B3vyHdgYmUm+++C/WZjjwSHnmkoIifkoRISpKNR9EYuBvYF/gAuN7dl2cqMJFy8fLLcOmlsGIFXH996LxWET+RbZKsRfEE8ArQnVBB9sGMRCRSXpYuhe7doW5dmDgR7roLtt8+7qhEKpxkfRS13X1Q9HyBmU3PREAiZeIO778PBx9cUMTv4INVn0mkDJK1KGqaWWsza2NmbYBahaZLZGZdzGyBmS00sxuTrNfdzNzMSnUziAgAy5bBySeHukz5Rfw6d1aSECmjZC2KL4B7EqZXJEw7cGSyDZtZVeAh4BhgGTDFzEa6+7xC69UGrgYmbVvoIpEtW2DQIOjfHzZtgnvugUMPjTsqkZyRbOCiI8q47XbAQndfBGBmwwgVaOcVWu8vwJ1A/zLuTyqr7t1hxIhwVdOgQfCbWAZfFMlZ6bxxrh6wNGF6WTTvZ9EprAbu/mqyDZlZHzObamZTN27cWP6RSsWzaVNBEb/u3UOCeOMNJQmRNIjtDuuoXPk9hMGQknL3ge6e5+551aqpwnmlN3t2GExoUHStxdlnh6J+ZslfJyKlks5EsRxokDBdP5qXrzbQHBhnZp8CHYCR6tCWYm3YALfcAm3bwmefqTaTSIakUj3WzOxsM/tTNN3QzNqlsO0pQGMza2Rm1YGewMj8he7+nbvv5u77uPs+wETgZHdXDXH5pSlTQpXX226Ds86C+fPhtNPijkqkUkilRfEw0BE4K5peQ7iaKSl33wRcAYwB5gPPuvtcM7vNzE4uZbxSWa1eDWvXwqhR8O9/h5voRCQjShy4yMymu3sbM5vh7q2jebPcvWVGIixEAxdVIm+9FYr4XX11mN6wQeU3REoprQMXARujeyI82tmvgC2l2ZlISr79Now0d9RR8NhjBUX8lCREYpFKongAeBHY3cz+CkwAbk9rVFJ5vfQSNG0KTzwB//d/YYAhJQiRWJU4HoW7P21m04CjAANOcff5aY9MKp8lS+CMM+DAA2HkSMjTBXAi2aDERGFmDYEfgZcT57n7knQGJpWEO0yYAIcdBg0bhpvmOnRQfSaRLJLKCHevEvonDKgJNAIWAM3SGJdUBkuWhLEiXnsNxo2DTp3g8MPjjkpECknl1NNBidNR2Y2+aYtIct+WLfDoo3DDDaFF8cADKuInksVSaVFsxd2nm1n7dAQjlcRpp4VO62OOgYEDYZ994o5IRJJIpY/iuoTJKkAb4PO0RSS5adMmqFIlPM48E7p1g969VZ9JpAJI5fLY2gmPGoQ+i27pDEpyzKxZ0L59aD1AKMFx/vlKEiIVRNIWRXSjXW13vz5D8UguWb8eBgyAO++EXXeFX/867ohEpBSKTRRmtp27bzKzQzIZkOSIyZPhvPPgww/Dz3vuCclCRCqcZC2KyYT+iJlmNhJ4Dvghf6G7v5Dm2KQi+/57WLcORo+G446LOxoRKYNUrnqqCawijJGdfz+FA0oUsrXXX4e5c+Haa+Hoo2HBApXfEMkByRLF7tEVT3MoSBD5kpeclcpl9Wq47joYMgSaNYO+fUOCUJIQyQnJrnqqCuwYPWonPM9/iMALL4Qifk89Bb//PUydqgQhkmOStSi+cPfbMhaJVDxLlkDPntC8eRhQqHXruCMSkTRI1qLQRe7yS+7w9tvhecOGYXChSZOUJERyWLJEcVTGopCK4bPP4PjjoXPngmRx6KFQrVqsYYlIehWbKNz9m0wGIllsyxb45z9DR/WECfDgg6EsuIhUCttcFFAqoVNOgZdfDvdDPPYY7L133BGJSAYpUUjRNm6EqlVDEb+zzoLTT4dzzlF9JpFKKJWigFLZTJ8O7dqFMSMgJAy3AuwAABKnSURBVIpzz1WSEKmklCikwLp14V6Idu1gxQpo0CDuiEQkC+jUkwQTJ4bifR99BBdcAHffDbvsEndUIpIFlCgk+OGH0C/xv/+FOk0iIhElisps9OhQxK9fPzjqqFASvHr1uKMSkSyjPorKaNWqcJrp+OPhySfhp5/CfCUJESmCEkVl4g7Dh4cifs88A3/4A0yZogQhIknp1FNlsmQJ9OoFLVqEsSNatow7IhGpANSiyHXuoXAfhDuqx40LVzgpSYhIipQoctnixXDssaGjOr+I38EHw3ZqSIpI6pQoctHmzXD//WGciEmT4JFHVMRPREpNXy1zUbdu8Oqr0LVrKMOhO6xFpAyUKHJFYhG/c84J9Zl69VJ9JhEps7SeejKzLma2wMwWmtmNRSy/zszmmdlsM3vTzFS/ujSmToW8vHCKCeDMM+F3v1OSEJFykbZEYWZVgYeA44GmwFlm1rTQajOAPHdvAQwH/p6ueHLSunVwww3Qvj2sXKlxIkQkLdLZomgHLHT3Re7+EzAM6Ja4gruPdfcfo8mJQP00xpNb3n8/XOL697+HIn7z5sGJJ8YdlYjkoHT2UdQDliZMLwPaJ1n/QuC1ohaYWR+gD0CNGi3KK76Kbd26METpG2+Ey19FRNIkKzqzzexsIA/oVNRydx8IDASoXTvPMxhadhk1KhTx698fjjwS5s+HatXijkpEclw6Tz0tBxKvy6wfzduKmR0N3Ayc7O4b0hhPxfX113D22XDCCfD00wVF/JQkRCQD0pkopgCNzayRmVUHegIjE1cws9bAY4Qk8VUaY6mY3GHYMDjwQHj2WbjlFpg8WUX8RCSj0nbqyd03mdkVwBigKvCEu881s9uAqe4+ErgL2BF4zsKlnEvc/eR0xVThLFkSyoG3bAmPPw4HHRR3RCJSCZl7xTrlX7t2nq9ZMzXuMNLHHd58s2CUuYkT4be/DTfTiYiUkplNc/e80rxWtZ6yySefhCuYjjmmoIhfhw5KEiISKyWKbLB5M9xzTzi1NG0aPPaYiviJSNbIistjK72TToLXXgs3zD3yCNTXfYcikj2UKOLy009hXIgqVaB371DIr2dP1WcSkayjU09xmDwZ2raFhx8O0z16hGqvShIikoWUKDLpxx+hXz/o2BFWr4Z99407IhGREunUU6ZMmBDuiVi0CC65BO68E3baKe6oRERKpESRKfkDC40dC507xx2NiEjKlCjS6eWXQ+G+//s/OOKIUAp8Ox1yEalY1EeRDitXhmFITz4Zhg4tKOKnJCEiFZASRXlyh2eeCUX8hg+H226DSZNUxE9EKjR9xS1PS5bA+edD69ahiF+zZnFHJCJSZmpRlNWWLTBmTHi+997wzjvw7rtKEiKSM5QoyuLjj8NIc126wPjxYV67diriJyI5RYmiNDZtgrvughYtYObMcJpJRfxEJEepj6I0TjwxnG7q1i2U4dhrr7gjEslKGzduZNmyZaxfvz7uUCqNmjVrUr9+faqV41DJGrgoVRs2hDGqq1QJVzRt2QJnnKH6TCJJLF68mNq1a1O3bl1M/ytp5+6sWrWKNWvW0KhRo62WaeCidJs4Edq0gYceCtOnnx4K+ekPXySp9evXK0lkkJlRt27dcm/BKVEk88MPcO21cPDBsGYNNG4cd0QiFY6SRGal43irj6I477wTivgtXgx9+8Idd0CdOnFHJSKScWpRFGfTptAn8fbb4ZSTkoRIhTVixAjMjA8//PDneePGjePEE0/car3evXszfPhwIHTE33jjjTRu3Jg2bdrQsWNHXnvttTLHcscdd7Dffvux//77Myb/HqxC3nzzTdq0aUOrVq049NBDWbhwIQBLlizhiCOOoHXr1rRo0YJRo0aVOZ5UKFEkGjEitBwgFPGbOxcOPzzemESkzIYOHcqhhx7K0KFDU37NH//4R7744gvmzJnD9OnTGTFiBGvWrClTHPPmzWPYsGHMnTuX0aNH07dvXzZv3vyL9S677DKefvppZs6cSa9evRgwYAAAAwYMoEePHsyYMYNhw4bRt2/fMsWTKp16AvjyS7jySnjuudBp3a9fqM+kIn4i5eaaa8JtR+WpVSu4777k66xdu5YJEyYwduxYTjrpJP785z+XuN0ff/yRQYMGsXjxYmrUqAHAHnvsQY8ePcoU70svvUTPnj2pUaMGjRo1Yr/99mPy5Ml07Nhxq/XMjO+//x6A7777jr2iS/CLm59ulfuT0B3+85/wF7x2Lfz1r9C/fzjlJCI54aWXXqJLly40adKEunXrMm3aNNq2bZv0NQsXLqRhw4bUSeGU87XXXsvYsWN/Mb9nz57ceOONW81bvnw5HTp0+Hm6fv36LF++/BevHTx4MF27dqVWrVrUqVOHiRMnAnDrrbdy7LHH8uCDD/LDDz/wxhtvlBhfeajciWLJErjoIsjLC3dXH3BA3BGJ5KySvvmny9ChQ7n66quB8OE9dOhQ2rZtW+zVQdt61dC9995b5hiL2uaoUaNo3749d911F9dddx2DBw9m6NCh9O7dm379+vH+++9zzjnnMGfOHKpUSW8vQuVLFPlF/I4/PhTxe/fdUO1V9ZlEcs4333zDW2+9xQcffICZsXnzZsyMu+66i7p167J69epfrL/bbrux3377sWTJEr7//vsSWxXb0qKoV68eS5cu/Xl62bJl1KtXb6t1Vq5cyaxZs2jfvj0AZ555Jl26dAHg8ccfZ/To0QB07NiR9evX8/XXX7P77runeERKyd0r1GPHHdt6qS1Y4H7YYe7gPm5c6bcjIimZN29erPt/7LHHvE+fPlvNO/zww/3tt9/29evX+z777PNzjJ9++qk3bNjQv/32W3d379+/v/fu3ds3bNjg7u5fffWVP/vss2WKZ86cOd6iRQtfv369L1q0yBs1auSbNm3aap2NGzd63bp1fcGCBe7uPnjwYD/ttNPc3b1Lly7+r3/9y93Dsd1zzz19y5Ytv9hPUccdmOql/NyN/YN/Wx+lShQbN7r/7W/uNWq477yz+7/+5V7EwRWR8hV3oujcubO/9tprW827//77/dJLL3V39wkTJnj79u29ZcuWnpeX56+//vrP623YsMH79+/v++67rzdr1szbtWvno0ePLnNMAwYM8N/85jfepEkTHzVq1M/zjz/+eF++fLm7u7/wwgvevHlzb9GihXfq1Mk/+eQTd3efO3euH3zwwd6iRQtv2bKljxkzpsh9lHeiqBy1no47Dl5/HU47LdwT8etfpyc4EdnK/PnzOfDAA+MOo9Ip6riXpdZT7vZRrF8frl6qWhX69AmP7t3jjkpEpMLJzRvu3n03XGCdX8Sve3clCRGRUsqtRLF2LVx1VRhEaP16UJNXJHYV7fR2RZeO4507ieLtt6F5c/jnP+GKK2DOHDjmmLijEqnUatasyapVq5QsMsSj8Shq1qxZrtvNrT6K7bcPVV8POSTuSESEcOfxsmXLWLlyZdyhVBr5I9yVp4p91dMLL8CHH8JNN4XpzZt145yISBGydoQ7M+tiZgvMbKGZ3VjE8hpm9t9o+SQz2yelDa9YEUaZ694dXnwRfvopzFeSEBEpd2lLFGZWFXgIOB5oCpxlZk0LrXYhsNrd9wPuBe4sabs7bVwVOqlfeSWUBH/vvVDpVURE0iKdLYp2wEJ3X+TuPwHDgG6F1ukGPBk9Hw4cZSVU5Npjw2eh03rWLLjxRlV6FRFJs3R2ZtcDliZMLwPaF7eOu28ys++AusDXiSuZWR+gTzS5wSZMmKNKrwDsRqFjVYnpWBTQsSigY1Fg/9K+sEJc9eTuA4GBAGY2tbQdMrlGx6KAjkUBHYsCOhYFzGwbax8VSOepp+VAg4Tp+tG8Itcxs+2AnYBVaYxJRES2UToTxRSgsZk1MrPqQE9gZKF1RgLnRc9PB97yina9rohIjkvbqaeoz+EKYAxQFXjC3eea2W2EcrcjgceBp8xsIfANIZmUZGC6Yq6AdCwK6FgU0LEooGNRoNTHosLdcCciIpmVO7WeREQkLZQoREQkqaxNFGkr/1EBpXAsrjOzeWY228zeNLO944gzE0o6FgnrdTczN7OcvTQylWNhZj2iv425ZvZMpmPMlBT+Rxqa2VgzmxH9n3SNI850M7MnzOwrM5tTzHIzswei4zTbzNqktOHSjqGazgeh8/sT4DdAdWAW0LTQOn2BR6PnPYH/xh13jMfiCGD76PlllflYROvVBsYDE4G8uOOO8e+iMTAD2CWa3j3uuGM8FgOBy6LnTYFP4447TcficKANMKeY5V2B1wADOgCTUtlutrYo0lL+o4Iq8Vi4+1h3/zGanEi4ZyUXpfJ3AfAXQt2w9ZkMLsNSORYXAw+5+2oAd/8qwzFmSirHwoE60fOdgM8zGF/GuPt4whWkxekG/NuDicDOZrZnSdvN1kRRVPmPesWt4+6bgPzyH7kmlWOR6ELCN4ZcVOKxiJrSDdz91UwGFoNU/i6aAE3M7F0zm2hmXTIWXWalcixuBc42s2XAKODKzISWdbb18wSoICU8JDVmdjaQB3SKO5Y4mFkV4B6gd8yhZIvtCKefOhNamePN7CB3/zbWqOJxFjDE3f9hZh0J9281d/ctcQdWEWRri0LlPwqkciwws6OBm4GT3X1DhmLLtJKORW2gOTDOzD4lnIMdmaMd2qn8XSwDRrr7RndfDHxESBy5JpVjcSHwLIC7vw/UJBQMrGxS+jwpLFsThcp/FCjxWJhZa+AxQpLI1fPQUMKxcPfv3H03d9/H3fch9Nec7O6lLoaWxVL5HxlBaE1gZrsRTkUtymSQGZLKsVgCHAVgZgcSEkVlHJ91JHBudPVTB+A7d/+ipBdl5aknT1/5jwonxWNxF7Aj8FzUn7/E3U+OLeg0SfFYVAopHosxwLFmNg/YDPR395xrdad4LPoBg8zsWkLHdu9c/GJpZkMJXw52i/pjbgGqAbj7o4T+ma7AQuBH4PyUtpuDx0pERMpRtp56EhGRLKFEISIiSSlRiIhIUkoUIiKSlBKFiIgkpUQhWcnMNpvZzITHPknWXVsO+xtiZoujfU2P7t7d1m0MNrOm0fObCi17r6wxRtvJPy5zzOxlM9u5hPVb5WqlVMkcXR4rWcnM1rr7juW9bpJtDAFecffhZnYscLe7tyjD9socU0nbNbMngY/c/a9J1u9NqKB7RXnHIpWHWhRSIZjZjtFYG9PN7AMz+0XVWDPb08zGJ3zjPiyaf6yZvR+99jkzK+kDfDywX/Ta66JtzTGza6J5O5jZq2Y2K5p/ZjR/nJnlmdnfgFpRHE9Hy9ZGP4eZ2QkJMQ8xs9PNrKqZ3WVmU6JxAi5J4bC8T1TQzczaRe9xhpm9Z2b7R3cp3wacGcVyZhT7E2Y2OVq3qOq7IluLu366HnoU9SDcSTwzerxIqCJQJ1q2G+HO0vwW8droZz/g5uh5VULtp90IH/w7RPNvAP5UxP6GAKdHz88AJgFtgQ+AHQh3vs8FWgPdgUEJr90p+jmOaPyL/JgS1smP8VTgyeh5dUIlz1pAH+AP0fwawFSgURFxrk14f88BXaLpOsB20fOjgeej572Bfya8/nbg7Oj5zoT6TzvE/fvWI7sfWVnCQwRY5+6t8ifMrBpwu5kdDmwhfJPeA1iR8JopwBPRuiPcfaaZdSIMVPNuVN6kOuGbeFHuMrM/EGoAXUioDfSiu/8QxfACcBgwGviHmd1JOF31zja8r9eA+82sBtAFGO/u66LTXS3M7PRovZ0IBfwWF3p9LTObGb3/+cD/EtZ/0swaE0pUVCtm/8cCJ5vZ9dF0TaBhtC2RIilRSEXxO+BXQFt332ihOmzNxBXcfXyUSE4AhpjZPcBq4H/uflYK++jv7sPzJ8zsqKJWcvePLIx70RUYYGZvuvttqbwJd19vZuOA44AzCYPsQBhx7Ep3H1PCJta5eysz255Q2+hy4AHCYE1j3f3UqON/XDGvN6C7uy9IJV4RUB+FVBw7AV9FSeII4BfjglsYK/xLdx8EDCYMCTkROMTM8vscdjCzJinu8x3gFDPb3sx2IJw2esfM9gJ+dPf/EAoyFjXu8MaoZVOU/xKKseW3TiB86F+W/xozaxLts0geRjS8CuhnBWX288tF905YdQ3hFFy+McCVFjWvLFQeFklKiUIqiqeBPDP7ADgX+LCIdToDs8xsBuHb+v3uvpLwwTnUzGYTTjsdkMoO3X06oe9iMqHPYrC7zwAOAiZHp4BuAQYU8fKBwOz8zuxCXicMLvWGh6E7ISS2ecB0M5tDKBuftMUfxTKbMCjP34E7ovee+LqxQNP8zmxCy6NaFNvcaFokKV0eKyIiSalFISIiSSlRiIhIUkoUIiKSlBKFiIgkpUQhIiJJKVGIiEhSShQiIpLU/wPvtLiiP4ZC1wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute predicted probabilities on the test set\n",
    "probs = bert_predict(ctbert_classifier, val_dataloader)\n",
    "\n",
    "# Evaluate the Bert classifier\n",
    "evaluate_roc(probs, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_accuracy,y_pred= evaluate(ctbert_classifier, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_preds=[]\n",
    "for i in y_pred:\n",
    "    b=i.cpu().detach().numpy()\n",
    "    np_preds=np.append(np_preds,b,axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_preds=np_preds.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.74      0.70      0.72        20\n",
      "        real       0.77      0.80      0.78        25\n",
      "\n",
      "   micro avg       0.76      0.76      0.76        45\n",
      "   macro avg       0.75      0.75      0.75        45\n",
      "weighted avg       0.75      0.76      0.75        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_names = ['fake', 'real']\n",
    "print(classification_report(y_val, np_preds, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_confusion_matrix(confusion_matrix):\n",
    "      hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "      hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
    "      hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
    "      plt.ylabel('True ')\n",
    "      plt.xlabel('Predicted');\n",
    "cm = confusion_matrix(y_val, np_preds)\n",
    "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "show_confusion_matrix(df_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_tweets=[]\n",
    "for i in X:\n",
    "    preprocessed_tweets.append(text_preprocessing(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# create the transform\n",
    "vectorizer = CountVectorizer()\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(preprocessed_tweets)\n",
    "# summarize\n",
    "# encode document\n",
    "vector = vectorizer.transform(preprocessed_tweets)\n",
    "feature_names=vectorizer.get_feature_names()\n",
    "# summarize encoded vector\n",
    "f1=vector.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self,RSEED=50,MAX_DEPTH=20,n_estimators=100):\n",
    "        self.rseed=RSEED \n",
    "        self.max_depth=MAX_DEPTH\n",
    "        self.n_estimators=n_estimators\n",
    "    def train(self,X,y):\n",
    "        model = RandomForestClassifier(n_estimators=self.n_estimators, \n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt')\n",
    "#         # Fit on training data\n",
    "        indices = np.arange(len(X))\n",
    "        train_idx, test_idx, y_train, y_test= train_test_split(indices, y,stratify = y, test_size=0.1, random_state=42)\n",
    "        train_X = X[train_idx]\n",
    "        test_X = X[test_idx]\n",
    "        model=model.fit(train_X,y_train)\n",
    "\n",
    "        return model,test_X, y_test,y_train,train_X,train_idx, test_idx\n",
    "\n",
    "    def evaluate(self,model,test_X, y_test,y_train,train_X):\n",
    "        \"\"\"Compare machine learning model to baseline performance.\n",
    "        Computes statistics and shows ROC curve.\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        print(f'Model Accuracy: {model.score(test_X, y_test)}')\n",
    "        train_probs = model.predict_proba(train_X)[:, 1]\n",
    "        probs = model.predict_proba(test_X)[:, 1]\n",
    "\n",
    "        train_predictions = model.predict(train_X)\n",
    "        predictions = model.predict(test_X)\n",
    "\n",
    "\n",
    "        print(f'Train ROC AUC Score: {roc_auc_score(y_train, train_probs)}')\n",
    "        print(f'Test ROC AUC  Score: {roc_auc_score(y_test, probs)}')\n",
    "        \n",
    "\n",
    "\n",
    "#         results['recall'] = recall_score(y_test, predictions, average=\"binary\", pos_label='Fake')\n",
    "#         results['precision'] = precision_score(y_test, predictions, average=\"binary\", pos_label='Fake')\n",
    "#         results['roc'] = roc_auc_score(y_test, probs)\n",
    "#         print(results)\n",
    "        return y_test,predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForest(RSEED=50,MAX_DEPTH=20,n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.7857142857142857\n",
      "Train ROC AUC Score: 0.999940880874963\n",
      "Test ROC AUC  Score: 0.8764302059496567\n"
     ]
    }
   ],
   "source": [
    "clf,test_X, y_test,y_train,train_X,train_idx, test_idx=rf.train(f1,y)\n",
    "y_test,predictions=rf.evaluate(clf,test_X, y_test,y_train,train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.92      0.58      0.71        19\n",
      "        real       0.73      0.96      0.83        23\n",
      "\n",
      "   micro avg       0.79      0.79      0.79        42\n",
      "   macro avg       0.82      0.77      0.77        42\n",
      "weighted avg       0.82      0.79      0.78        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_names = ['fake', 'real']\n",
    "print(classification_report(y_test, predictions, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, predictions)\n",
    "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "show_confusion_matrix(df_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
