{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from bertmodel import *\n",
    "from fcclassifier import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "Device name: GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    \"\"\"\n",
    "    - Remove entity mentions (eg. '@united')\n",
    "    - Correct errors (eg. '&amp;' to '&')\n",
    "    @param    text (str): a string to be processed.\n",
    "    @return   text (Str): the processed string.\n",
    "    \"\"\"\n",
    "    # Remove '@name'\n",
    "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    # Replace '&amp;' with '&'\n",
    "    text = re.sub(r'&amp;', '&', text)\n",
    "\n",
    "    # Remove trailing whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text=text.replace(\"#\",\"\")\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/nazaninjafar/ds4cg2020/bert-covid/data/alldata2.tsv')\n",
    "meta_data=pd.read_csv('/home/nazaninjafar/ds4cg2020/bert-covid/data/user_metadata.tsv')\n",
    "meta_data=meta_data.replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "def norm(X):\n",
    "    X=normalize(X, axis=0, norm='max')\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User metadata features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = np.expand_dims((meta_data.friend_count.values), axis=1)\n",
    "fwc = np.expand_dims(meta_data.follower_count.values, axis=1)\n",
    "favc = np.expand_dims(meta_data.fav_count.values, axis=1)\n",
    "tc = np.expand_dims(meta_data.tweet_count.values, axis=1)\n",
    "TFF=fc+1/fwc+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "creation_times=meta_data.created.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-03 13:20:10.573291\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from datetime import timedelta\n",
    "# import datetime\n",
    "\n",
    "today = datetime.datetime.today()\n",
    "print(today)\n",
    "time_difference=[]\n",
    "for a in creation_times:\n",
    "    account_date=datetime.datetime.strptime(a, '%Y-%m-%d %H:%M:%S')\n",
    "    time_difference.append((today - account_date).days)\n",
    "#     print(time_difference)\n",
    "# age=[(today - account_date).days for ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "age=np.array(time_difference).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_X=np.concatenate((favc,tc,TFF,age),axis=1)\n",
    "md_X=norm(md_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.tweet.values\n",
    "y = data.label.values\n",
    "indices = np.arange(len(X))\n",
    "train_idx, val_idx, y_train, y_val= train_test_split(indices, y,stratify = y, test_size=0.1, random_state=42)\n",
    "X_train = X[train_idx]\n",
    "X_val = X[val_idx]\n",
    "mdX_train = md_X[train_idx]\n",
    "mdX_val = md_X[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# X_train, X_val, y_train, y_val =\\\n",
    "#     train_test_split(X, y,stratify = y, test_size=0.1, random_state=42)\n",
    "# mdX_train, mdX_val, y_train, y_val =\\\n",
    "#     train_test_split(md_X, y,stratify = y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "# Create a function to tokenize a set of texts\n",
    "def preprocessing_for_ctbert(data,max_len):\n",
    "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
    "    @param    data (np.array): Array of texts to be processed.\n",
    "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
    "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
    "                  tokens should be attended to by the model.\n",
    "    \"\"\"\n",
    "    # Create empty lists to store outputs\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in data:\n",
    "        # `encode_plus` will:\n",
    "        #    (1) Tokenize the sentence\n",
    "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
    "        #    (3) Truncate/Pad sentence to max length\n",
    "        #    (4) Map tokens to their IDs\n",
    "        #    (5) Create attention mask\n",
    "        #    (6) Return a dictionary of outputs\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text=text_preprocessing(sent),  # Preprocess sentence\n",
    "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
    "            max_length=max_len,                  # Max length to truncate/pad\n",
    "            pad_to_max_length=True,         # Pad sentence to max length\n",
    "            #return_tensors='pt',           # Return PyTorch tensor\n",
    "            return_attention_mask=True,     # Return attention mask\n",
    "            truncation=True\n",
    "            )\n",
    "        \n",
    "        # Add the outputs to the lists\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data...\n"
     ]
    }
   ],
   "source": [
    "print('Tokenizing data...')\n",
    "max_len = 160\n",
    "train_inputs, train_masks = preprocessing_for_ctbert(X_train,max_len)\n",
    "val_inputs, val_masks = preprocessing_for_ctbert(X_val,max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Convert other data types to torch.Tensor\n",
    "train_labels = torch.tensor(y_train)\n",
    "val_labels = torch.tensor(y_val)\n",
    "\n",
    "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "# # Create the DataLoader for our training set\n",
    "# train_data = TensorDataset(train_inputs, train_masks,traind_inputs, traind_masks, train_labels)\n",
    "# train_sampler = RandomSampler(train_data)\n",
    "# train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# # Create the DataLoader for our validation set\n",
    "# val_data = TensorDataset(val_inputs, val_masks,vald_inputs, vald_masks, val_labels)\n",
    "# val_sampler = SequentialSampler(val_data)\n",
    "# val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "\n",
    "md_train=torch.tensor(mdX_train).type(torch.FloatTensor)\n",
    "md_val=torch.tensor(mdX_val).type(torch.FloatTensor)\n",
    "\n",
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(train_inputs, train_masks,md_train, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set\n",
    "val_data = TensorDataset(val_inputs, val_masks,md_val, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningrate=5e-5\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from fcclassifier import *\n",
    "def initialize_model(epochs=4,lr=learningrate):\n",
    "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
    "    \"\"\"\n",
    "    # Instantiate Bert Classifier\n",
    "#     bert_model = BertM(freeze_bert=False)\n",
    "\n",
    "    # Tell PyTorch to run the model on GPU\n",
    "    classifier=MergedClassifier()\n",
    "    \n",
    "    classifier.to(device)\n",
    "    # Create the optimizer\n",
    "    optimizer = AdamW(classifier.parameters(),\n",
    "                      lr=learningrate,    # Default learning rate\n",
    "                      eps=1e-8    # Default epsilon value\n",
    "                      )\n",
    "\n",
    "    # Total number of training steps\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    # Set up the learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=0, # Default value\n",
    "                                                num_training_steps=total_steps)\n",
    "    return classifier, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import torch.nn as nn\n",
    "\n",
    "# Specify loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train(classifier, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
    "    \"\"\"Train the BertClassifier model.\n",
    "    \"\"\"\n",
    "    # Start training loop\n",
    "    print(\"Start training...\\n\")\n",
    "    for epoch_i in range(epochs):\n",
    "        # =======================================\n",
    "        #               Training\n",
    "        # =======================================\n",
    "        # Print the header of the result table\n",
    "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} |{'Train Acc':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "        print(\"-\"*70)\n",
    "\n",
    "        # Measure the elapsed time of each epoch\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "        # Reset tracking variables at the beginning of each epoch\n",
    "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "\n",
    "        # Put the model into the training mode\n",
    "        classifier.train()\n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch_counts +=1\n",
    "            # Load batch to GPU\n",
    "            b_input_ids, b_attn_mask,b_md, b_labels = tuple(t.to(device) for t in batch)\n",
    "            \n",
    "            # Zero out any previously calculated gradients\n",
    "#             bertmodel.zero_grad()\n",
    "            classifier.zero_grad()\n",
    "            # Perform a forward pass. This will return logits.\n",
    "            logits = classifier(b_input_ids, b_attn_mask,b_md)\n",
    "            \n",
    "#             #concatenating the hidden state with metadata:\n",
    "#             out=torch.cat((h_state,b_md),axis=1)\n",
    "#             print(out.size())  \n",
    "              \n",
    "#             logits = classifier(out)\n",
    "            # Compute loss and accumulate the loss values\n",
    "            loss = loss_fn(logits, b_labels)\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "            torch.nn.utils.clip_grad_norm_(classifier.parameters(), 1.0)\n",
    "\n",
    "            # Update parameters and the learning rate\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Print the loss values and time elapsed for every 20 batches\n",
    "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
    "                # Calculate time elapsed for 20 batches\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "\n",
    "                # Print training results\n",
    "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "                # Reset batch tracking variables\n",
    "                batch_loss, batch_counts = 0, 0\n",
    "                t0_batch = time.time()\n",
    "\n",
    "        # Calculate the average loss over the entire training data\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        print(\"-\"*70)\n",
    "        # =======================================\n",
    "        #               Evaluation\n",
    "        # =======================================\n",
    "        if evaluation == True:\n",
    "            # After the completion of each training epoch, measure the model's performance\n",
    "            # on our validation set.\n",
    "            val_loss, val_accuracy,_ = evaluate(classifier, val_dataloader)\n",
    "            _,train_accuracy,_=evaluate(classifier,train_dataloader)\n",
    "            # Print performance over the entire training data\n",
    "            time_elapsed = time.time() - t0_epoch\n",
    "            \n",
    "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {train_accuracy:^9.2f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "            print(\"-\"*70)\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "\n",
    "\n",
    "def evaluate(classifier, val_dataloader):\n",
    "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
    "    on our validation set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    classifier.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "    preds=[]\n",
    "\n",
    "    for batch in val_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask,b_md, b_labels = tuple(t.to(device) for t in batch)\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = classifier(b_input_ids, b_attn_mask,b_md)\n",
    "            #concatenating the hidden state with metadata:\n",
    "#             out=torch.cat((h_state,b_md),axis=1)\n",
    "            \n",
    "#             logits = classifier(out)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(logits, b_labels)\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "        # Get the predictions\n",
    "        pred= torch.argmax(logits, dim=1).flatten()\n",
    "        preds.append(pred)\n",
    "        # Calculate the accuracy rate\n",
    "        accuracy = (pred == b_labels).cpu().numpy().mean() * 100\n",
    "        val_accuracy.append(accuracy)\n",
    "\n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "    return val_loss, val_accuracy,preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   12    |   0.709517   |     -      |     -     |   4.19   \n",
      "----------------------------------------------------------------------\n",
      "   1    |    -    |   0.709517   |   56.09   |  0.665759  |   59.62   |   5.63   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   12    |   0.660534   |     -      |     -     |   4.17   \n",
      "----------------------------------------------------------------------\n",
      "   2    |    -    |   0.660534   |   83.59   |  0.594150  |   76.68   |   5.61   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   3    |   12    |   0.545351   |     -      |     -     |   4.25   \n",
      "----------------------------------------------------------------------\n",
      "   3    |    -    |   0.545351   |   93.72   |  0.470161  |   82.09   |   5.71   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   4    |   12    |   0.396926   |     -      |     -     |   4.25   \n",
      "----------------------------------------------------------------------\n",
      "   4    |    -    |   0.396926   |   94.44   |  0.511942  |   78.97   |   5.71   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   5    |   12    |   0.319766   |     -      |     -     |   4.22   \n",
      "----------------------------------------------------------------------\n",
      "   5    |    -    |   0.319766   |   98.56   |  0.424748  |   86.78   |   5.69   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   6    |   12    |   0.289970   |     -      |     -     |   4.22   \n",
      "----------------------------------------------------------------------\n",
      "   6    |    -    |   0.289970   |   98.53   |  0.445693  |   81.37   |   5.69   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   7    |   12    |   0.267655   |     -      |     -     |   4.25   \n",
      "----------------------------------------------------------------------\n",
      "   7    |    -    |   0.267655   |   98.04   |  0.443739  |   83.65   |   5.72   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   8    |   12    |   0.249595   |     -      |     -     |   4.20   \n",
      "----------------------------------------------------------------------\n",
      "   8    |    -    |   0.249595   |   98.77   |  0.445172  |   86.78   |   5.68   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   9    |   12    |   0.236566   |     -      |     -     |   4.24   \n",
      "----------------------------------------------------------------------\n",
      "   9    |    -    |   0.236566   |   99.28   |  0.515702  |   81.37   |   5.71   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  10    |   12    |   0.231185   |     -      |     -     |   4.22   \n",
      "----------------------------------------------------------------------\n",
      "  10    |    -    |   0.231185   |   99.52   |  0.558892  |   77.52   |   5.69   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  11    |   12    |   0.221524   |     -      |     -     |   4.20   \n",
      "----------------------------------------------------------------------\n",
      "  11    |    -    |   0.221524   |   99.52   |  0.590233  |   81.37   |   5.67   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  12    |   12    |   0.224335   |     -      |     -     |   4.23   \n",
      "----------------------------------------------------------------------\n",
      "  12    |    -    |   0.224335   |   99.52   |  0.493437  |   81.37   |   5.71   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  13    |   12    |   0.214998   |     -      |     -     |   4.25   \n",
      "----------------------------------------------------------------------\n",
      "  13    |    -    |   0.214998   |   99.28   |  0.658796  |   78.25   |   5.73   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  14    |   12    |   0.209676   |     -      |     -     |   4.26   \n",
      "----------------------------------------------------------------------\n",
      "  14    |    -    |   0.209676   |   99.52   |  0.461244  |   80.65   |   5.74   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  15    |   12    |   0.213772   |     -      |     -     |   4.26   \n",
      "----------------------------------------------------------------------\n",
      "  15    |    -    |   0.213772   |   99.52   |  0.591070  |   81.37   |   5.74   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  16    |   12    |   0.211510   |     -      |     -     |   4.26   \n",
      "----------------------------------------------------------------------\n",
      "  16    |    -    |   0.211510   |   99.52   |  0.625953  |   79.81   |   5.74   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  17    |   12    |   0.206840   |     -      |     -     |   4.27   \n",
      "----------------------------------------------------------------------\n",
      "  17    |    -    |   0.206840   |   99.52   |  0.554810  |   80.65   |   5.75   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  18    |   12    |   0.205740   |     -      |     -     |   4.27   \n",
      "----------------------------------------------------------------------\n",
      "  18    |    -    |   0.205740   |   99.52   |  0.552580  |   80.65   |   5.76   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  19    |   12    |   0.207232   |     -      |     -     |   4.21   \n",
      "----------------------------------------------------------------------\n",
      "  19    |    -    |   0.207232   |   99.52   |  0.570859  |   79.09   |   5.69   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Acc   |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  20    |   12    |   0.200943   |     -      |     -     |   4.31   \n",
      "----------------------------------------------------------------------\n",
      "  20    |    -    |   0.200943   |   99.52   |  0.578050  |   79.09   |   5.79   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters:\n",
    "epochs=20\n",
    "learningrate=5e-5\n",
    "set_seed(42)    # Set seed for reproducibility\n",
    "# BERTDIM=768\n",
    "classifier, optimizer, scheduler = initialize_model(epochs,learningrate)\n",
    "train(classifier, train_dataloader, val_dataloader, epochs, evaluation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_accuracy,y_pred= evaluate(classifier, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_preds=[]\n",
    "for i in y_pred:\n",
    "    b=i.cpu().detach().numpy()\n",
    "    np_preds=np.append(np_preds,b,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_preds=np_preds.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.82      0.70      0.76        20\n",
      "        real       0.79      0.88      0.83        25\n",
      "\n",
      "   micro avg       0.80      0.80      0.80        45\n",
      "   macro avg       0.80      0.79      0.79        45\n",
      "weighted avg       0.80      0.80      0.80        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_names = ['fake', 'real']\n",
    "print(classification_report(y_val, np_preds, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_confusion_matrix(confusion_matrix):\n",
    "      hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "      hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
    "      hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
    "      plt.ylabel('True ')\n",
    "      plt.xlabel('Predicted');\n",
    "cm = confusion_matrix(y_val, np_preds)\n",
    "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "show_confusion_matrix(df_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "\n",
    "def evaluate_roc(probs, y_true):\n",
    "    \"\"\"\n",
    "    - Print AUC and accuracy on the test set\n",
    "    - Plot ROC\n",
    "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
    "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
    "    \"\"\"\n",
    "    preds = probs[:, 1]\n",
    "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f'AUC: {roc_auc:.4f}')\n",
    "       \n",
    "    # Get accuracy over the test set\n",
    "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "    \n",
    "    # Plot ROC AUC\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def bert_predict(model, test_dataloader):\n",
    "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
    "    on the test set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    all_logits = []\n",
    "\n",
    "    # For each batch in our test set...\n",
    "    for batch in test_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask,b_md,b_label = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask,b_md)\n",
    "        all_logits.append(logits)\n",
    "    \n",
    "    # Concatenate logits from each batch\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "\n",
    "    # Apply softmax to calculate probabilities\n",
    "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9080\n",
      "Accuracy: 80.00%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd5gUVdbH8e8BSSKigpGgqKgEERFFMKAgioiiCyJmTBjXhK5p9zUsuwaUNSwqGBbXAKuoiBFXAREVEASRIIqgBMWAqCBBBs77x63ZacaZnmZmeqq75/d5nn6mK3TV6ZqZPl11b51r7o6IiEhxqsQdgIiIZDYlChERSUqJQkREklKiEBGRpJQoREQkKSUKERFJSolCNouZzTazI+KOI1OY2Y1m9mhM+x5mZgPi2Hd5M7PTzezNUr5Wf5NppkSRxczsSzNbY2arzGxZ9MGxVTr36e4t3H18OveRz8xqmNntZrYoep+fm9m1ZmYVsf8i4jnCzJYkznP3v7v7+Wnan5nZ5WY2y8x+NbMlZvacme2bjv2VlpndYmZPlWUb7v60ux+dwr5+lxwr8m+yslKiyH7Hu/tWQGtgf+CGmOPZbGa2RTGLngM6A92AOsCZQD/gvjTEYGaWaf8P9wFXAJcD2wF7AaOA48p7R0l+B2kX574lRe6uR5Y+gC+BoxKm7wJeTZg+GHgf+An4GDgiYdl2wL+Ar4EVwKiEZd2BGdHr3gdaFd4nsAuwBtguYdn+wA9AtWj6XGButP0xwK4J6zpwKfA5sLCI99YZWAs0KjS/HbAB2DOaHg/cDkwBfgFeKhRTsmMwHvgb8F70XvYEzoliXgksAC6M1q0drbMRWBU9dgFuAZ6K1tktel9nA4uiY3FTwv5qAU9Ex2Mu8CdgSTG/26bR+zwoye9/GDAYeDWKdzKwR8Ly+4DF0XGZBhyWsOwWYCTwVLT8fOAg4IPoWH0D/BOonvCaFsB/gR+Bb4Ebga7Ab8D66Jh8HK1bF3gs2s5SYABQNVrWNzrm/wCWR8v6AhOj5RYt+y6K7ROgJeFLwvpof6uAlwv/HwBVo7i+iI7JNAr9DelRis+auAPQowy/vE3/QRpG/1D3RdMNon/CboQzxy7R9PbR8leB/wDbAtWAjtH8/aN/0HbRP93Z0X5qFLHPscAFCfEMBB6OnvcA5gPNgC2APwPvJ6zr0YfOdkCtIt7bHcA7xbzvryj4AB8ffRC1JHyYP0/BB3dJx2A84QO9RRRjNcK39T2iD6uOwGqgTbT+ERT6YKfoRPEIISnsB6wDmiW+p+iYNwRmFt5ewnYvAr4q4fc/LHo/B0XxPw2MSFh+BlAvWtYfWAbUTIh7PXBidGxqAQcQEusW0XuZC1wZrV+H8KHfH6gZTbcrfAwS9v0iMCT6nexASOT5v7O+QB7wx2hftdg0URxD+IDfJvo9NAN2TnjPA5L8H1xL+D/YO3rtfkC9uP9Xs/0RewB6lOGXF/5BVhG+OTnwNrBNtOw64MlC648hfPDvTPhmvG0R23wI+GuhefMoSCSJ/5TnA2Oj50b49np4NP06cF7CNqoQPnR3jaYd6JTkvT2a+KFXaNkkom/qhA/7OxKWNSd846ya7BgkvPa2Eo7xKOCK6PkRpJYoGiYsnwL0iZ4vAI5JWHZ+4e0lLLsJmFRCbMOARxOmuwGfJll/BbBfQtwTStj+lcCL0fNTgenFrPe/YxBN70hIkLUS5p0KjIue9wUWFdpGXwoSRSfgM0LSqlLEe06WKOYBPdLx/1aZH5l2TVY234nuXofwIbYPUD+avytwspn9lP8ADiUkiUbAj+6+oojt7Qr0L/S6RoTLLIU9D7Q3s52BwwnJ592E7dyXsI0fCcmkQcLrFyd5Xz9EsRZl52h5Udv5inBmUJ/kx6DIGMzsWDObZGY/Rut3o+CYpmpZwvPVQH4Hg10K7S/Z+19O8e8/lX1hZteY2Vwz+zl6L3XZ9L0Ufu97mdkrUceIX4C/J6zfiHA5JxW7En4H3yQc9yGEM4si953I3ccSLnsNBr4zs6FmtnWK+96cOCVFShQ5wt3fIXzbujuatZjwbXqbhEdtd78jWradmW1TxKYWA38r9Lot3X14EftcAbwJnAKcRjgD8ITtXFhoO7Xc/f3ETSR5S28B7cysUeJMM2tH+DAYmzA7cZ3GhEsqP5RwDH4Xg5nVICS/u4Ed3X0b4DVCgisp3lR8Q7jkVFTchb0NNDSztqXZkZkdRmgD6U04c9wG+JmC9wK/fz8PAZ8CTd19a8K1/vz1FwO7F7O7wttZTDijqJ9w3Ld29xZJXrPpBt3vd/cDCGeIexEuKZX4umjfe5SwjmwmJYrcci/Qxcz2IzRSHm9mx5hZVTOrGXXvbOju3xAuDT1oZtuaWTUzOzzaxiPARWbWLuoJVNvMjjOzOsXs8xngLKBX9Dzfw8ANZtYCwMzqmtnJqb4Rd3+L8GH5vJm1iN7DwdH7esjdP09Y/Qwza25mWwK3ASPdfUOyY1DMbqsDNYDvgTwzOxZI7LL5LVDPzOqm+j4KeZZwTLY1swbAZcWtGL2/B4HhUczVo/j7mNn1KeyrDqEd4HtgCzP7P6Ckb+V1CI3Hq8xsH+DihGWvADub2ZVRt+U6UdKGcFx2y+81Fv19vQncY2Zbm1kVM9vDzDqmEDdmdmD091cN+JXQqWFjwr6KS1gQLln+1cyaRn+/rcysXir7leIpUeQQd/8e+Dfwf+6+mNCgfCPhw2Ix4VtZ/u/8TMI3708JjddXRtuYClxAOPVfQWiQ7ptkt6MJPXSWufvHCbG8CNwJjIguY8wCjt3Mt9QTGAe8QWiLeYrQk+aPhdZ7knA2tYzQ0Hp5FENJx2AT7r4yeu2zhPd+WvT+8pd/CgwHFkSXVIq6HJfMbcASYCHhjGkk4Zt3cS6n4BLMT4RLKicBL6ewrzGE4/YZ4XLcWpJf6gK4hvCeVxK+MPwnf0F0bLoAxxOO8+fAkdHi56Kfy83so+j5WYTEO4dwLEeS2qU0CAntkeh1XxEuww2Mlj0GNI+O/6giXjuI8Pt7k5D0HiM0lksZWMGVApHsY2bjCQ2psdwdXRZmdjGhoTulb9oicdEZhUgFMbOdzeyQ6FLM3oSupi/GHZdISdKWKMzscTP7zsxmFbPczOx+M5tvZjPNrE26YhHJENUJvX9WEhrjXyK0Q4hktLRdeooaR1cB/3b3lkUs70a41tyNcHPXfe7ervB6IiISr7SdUbj7BELf+eL0ICQRd/dJwDZRf3wREckgcRbjasCmvTCWRPO+KbyimfUj1Hmhdu3aB+yzzz4VEqCIZK85c2DNmrijiF9jvmIbfmImeT+4+/al2UZWVG1096HAUIC2bdv61KlTY45IRDJd8+aw++7w8MNxRxKD/CYFM2r/+yGqLP+ObQbd8lVpNxdnoljKpnemNozmiYiUiy23hIbF3V6Zq5YuhUsuhlNOgdNPhxuj+yYH3VLqTcbZPXY0cFbU++lg4Ofojk4REdlc7vDII+FU6q23YNWqctt02s4ozGw4oVBdfQujgt1MKBSGuz9MqKHTjXDn72rCOAAiIrK5vvgCLrgAxo2DI48MCWOP8it5lbZE4e6nlrA8f+AaEREpi08+gWnTYOhQOP98KOfRgrOiMVtERAqZNQs++gjOOgtOPBEWLIB66al/qBIeIiLZ5Lff4JZboE0buOkmWLs2zE9TkgAlChGR7DF5ckgQt94aejVNnw41a6Z9t7r0JCKSDZYuhcMOgx13hFdegeOOq7Bd64xCRCSTffZZ+NmgAfznPzB7doUmCVCiEBHJTD/9BP36wT77wIQJYd5JJ8HWqQ4fXn506UlEJNOMHg0XXwzLlsG118KBB8YajhKFiEgmOf98eOwx2HdfeOklaNs27oiUKEREYpdQxI+2bWHXXeG666B69XjjiihRiIjEafFiuOgi6NMHzjwzPM8waswWEYnDxo3w0EPQogWMHw/r1sUdUbF0RiGV0saNoTzO22/D2LGhU8nKlXFHJeVtv/3ijqAYn38e2iImTICjjgo1mpo0iTuqYilRSKXgDvPnFySGcePghx/Csr32gtNOC/cxSW456aS4IyjGnDkwcyY8/jj07VvuRfzKmxKF5KylSwsSw9ix4VIwhPuWunWDzp1DReZGjZJvR6RcfPwxzJgBZ58NPXqEIn7bbht3VClRopCcsXx5uNSbnxzmzQvz69ULCeHGG6FTJ2jaNOO/wEkuWbcOBgyAO+6AnXcONZpq1syaJAFKFJLFVq2Cd98tSAwzZoRLTFttBYcfHm5q7dQJWrWCKuq2IXH44AM47zyYOzeUAx80qEKK+JU3JQrJGuvWwaRJBYlh8mTIywtdzTt0CAU1O3cON7FWqxZ3tFLpLV0KHTvCTjvBa6/BscfGHVGpKVFIxtqwIYzLkp8YJk6ENWvC2UHbtnDNNSExdOgAW24Zd7QikblzoVmz0Bj27LPhj7ROnbijKhMlCskY7qEzSH5iGD8efv45LGvZMgwJ3LlzuKy0zTaxhiryeytWQP/+8K9/hW6vhx0WRp7LAUoUWWrZMpg6Ne4oyseyZQU9k779NszbfXc4+eSCnknquioZ7cUX4ZJL4Pvv4YYbYi/iV96UKLLUpZfCCy/EHUX52WmnkBQ6dQo/d9st7ohEUnTuueEsonVrePXVMAJdjlGiyFKrV0Pz5vDEE3FHUnZbb60uq5JlEov4HXxw+AO+5pqc7UWhRJHFttoqIyoQi1QuX30FF14Ybuc/66zQDzvHqXe5iEgqNm6EwYNDz4qJE2H9+rgjqjA6oxARKcm8eaGI38SJcPTRMGRIpWpIU6IQESnJvHkwezYMGxYuN1WyBjUlChGRokyfHurCnHMOnHBCKOJXSW/gURuFiEiitWtDBckDD4RbbgnTUGmTBOiMYrP99hv85S/w00/xxjFrFuyyS7wxiOSc994LRfzmzQtnEvfck5VF/MqbEsVmmj0b7rorfLmI++/n8MPj3b9ITlm6NJQBaNAAxowJjdYCKFFstvz7bJ54Ily2FJEsN2dOuHu1QQN4/vmQLLbaKu6oMoraKESkcvrxxzAMaYsWoYgfwPHHK0kUQWcUIlL5PP98KJi2fDncdBMcdFDcEWU0JQoRqVz69g3Xjtu0gTfeCMX8JCklChHJfYlF/Dp0CAML9e8PW+gjMBVpbaMws65mNs/M5pvZ9UUsb2xm48xsupnNNLNu6YxHRCqhhQtDD6Z//ztM9+sH112nJLEZ0pYozKwqMBg4FmgOnGpmzQut9mfgWXffH+gDPJiueESkktmwAe6/PxTxmzSp4KxCNls6U+pBwHx3XwBgZiOAHsCchHUc2Dp6Xhf4uqSNfvwx7LxzOUe6GfILRlayUi8i2WXu3HDj3AcfwLHHwsMPQ+PGcUeVtdKZKBoAixOmlwDtCq1zC/Cmmf0RqA0cVdSGzKwf0A+gSpU2sd+/sOWWcOih8cYgIknMnx/urn7ySTj9dH2zK6O4L9KdCgxz93vMrD3wpJm1dPeNiSu5+1BgKECtWm19yJAYIhWRzDZtWrjkcO654X6IhQvD8IlSZulszF4KNEqYbhjNS3Qe8CyAu38A1ATqpzEmEck1a9bA9ddDu3bw178WFPFTkig36UwUHwJNzayJmVUnNFaPLrTOIqAzgJk1IySK79MYk4jkkgkTYL/94M47w/0R06fHX4QtB6Xt0pO755nZZcAYoCrwuLvPNrPbgKnuPhroDzxiZlcRGrb7uqtrgoikYOlS6NwZGjWCt94KzyUtLNs+l2vVautr1kyNOwwRicsnn8C++4bnr7wSivjVrh1vTFnAzKa5e9vSvFZFAUUkO/zwA5x5JrRqVVDEr3t3JYkKEHevJxGR5NzhuefgsstgxQq4+ebQcC0VRolCRDLb2WeH+yHatoW33y647CQVRolCRDJPYhG/jh3D5aYrr1R9ppiojUJEMsuCBXDUUTBsWJg+7zy45holiRgpUYhIZtiwAe69N1xa+vBDqKKPp0yhFC0i8ZszJ5TemDwZjjsuFPFr2DDuqCSiRCEi8Vu4EL74Ap55Bvr0URG/DKNEISLx+PBDmDEDLrggnEUsWAB16sQdlRRBFwFFpGKtXh0apw8+GG6/vaCIn5JExlKiEJGKM3586Op6zz3hTEJF/LKCLj2JSMVYsgS6dIFdd4WxY0ONJskKOqMQkfT6+OPws2FDeOklmDlTSSLLKFGISHp8/z2cdhq0bg3vvBPmdesWxhKWrKJLTyJSvtxhxAi4/HL4+We49VZo3z7uqKQMlChEpHydeSY8/XSo8PrYY9CiRdwRSRmlnCjMbEt3X53OYEQkS23cGG6SMwvtDwccEM4oqlaNOzIpByW2UZhZBzObA3waTe9nZg+mPTIRyQ7z54dhSP/1rzB93nlw1VVKEjkklcbsfwDHAMsB3P1j4PB0BiUiWSAvD+6+OxTxmz4dqlePOyJJk5QuPbn7Ytu09sqG9IQjIllh1iw45xyYOhV69IAHH4Rddok7KkmTVBLFYjPrALiZVQOuAOamNywRyWiLFsFXX4XeTb17q4hfjkslUVwE3Ac0AJYCbwKXpDMoEclAkyeHm+f69Qv3QyxYAFttFXdUUgFSaaPY291Pd/cd3X0Hdz8DaJbuwEQkQ/z6K1x9dbgX4q67YN26MF9JotJIJVE8kOI8Eck1Y8eGIn7/+AdcdBF89BHUqBF3VFLBir30ZGbtgQ7A9mZ2dcKirQH1exPJdUuWwDHHQJMmoQTH4ersWFkla6OoDmwVrZNYKP4XoFc6gxKRGE2fDvvvH4r4vfwydOwItWrFHZXEyNw9+Qpmu7r7VxUUT4lq1Wrra9ZMjTsMkdzz7bfhbupnnw3jRnTsGHdEUo7MbJq7ty3Na1Pp9bTazAYCLYD/jTDi7p1Ks0MRyTDuoTbTFVfAqlUwYAB06BB3VJJBUmnMfppQvqMJcCvwJfBhGmMSkYp02mmhkN/ee4cxrG+6CapVizsqySCpnFHUc/fHzOwKd38HeMfMlChEslliEb+jjw5dXy+9VPWZpEipnFGsj35+Y2bHmdn+wHZpjElE0umzz0KF18cfD9PnnKNKr5JUKmcUA8ysLtCfcP/E1sCVaY1KRMpfXh4MGgQ33ww1a6onk6SsxETh7q9ET38GjgQws0PSGZSIlLOZM+Hcc2HaNDjpJBg8GHbeOe6oJEsku+GuKtCbUOPpDXefZWbdgRuBWsD+FROiiJTZkiWweDE89xz07KkifrJZkrVRPAacD9QD7jezp4C7gbvcPaUkYWZdzWyemc03s+uLWae3mc0xs9lm9szmvgERKcb778PDD4fn+UX8evVSkpDNluzSU1uglbtvNLOawDJgD3dfnsqGozOSwUAXYAnwoZmNdvc5Ces0BW4ADnH3FWa2Q2nfiIhEVq0KXVwfeAD22CM0VteoAbVrxx2ZZKlkZxS/uftGAHdfCyxINUlEDgLmu/sCd/8NGAH0KLTOBcBgd18R7ee7zdi+iBT25pvQsmVIEpdeqiJ+Ui6SnVHsY2Yzo+cG7BFNG+Du3qqEbTcAFidMLwHaFVpnLwAze49QaPAWd3+j8IbMrB/QD6Batf1K2K1IJbV4MRx3XDiLmDABDj007ogkRyRLFBUx5sQWQFPgCKAhMMHM9nX3nxJXcvehwFAItZ4qIC6R7DFtGhxwADRqBK+9BocdFrq/ipSTYi89uftXyR4pbHsp0ChhumE0L9ESYLS7r3f3hcBnhMQhIiVZtgxOPhnatg1lwAG6dFGSkHKXyp3ZpfUh0NTMmphZdaAPMLrQOqMIZxOYWX3CpagFaYxJJPu5wxNPQPPmoQz43/+uIn6SVqncmV0q7p5nZpcBYwjtD4+7+2wzuw2Y6u6jo2VHm9kcYANw7WY2mItUPn36hFLghxwCjz4K++wTd0SS40ocjwLAzGoBjd19XvpDSk7jUUillFjE74knYOVKuOQSqJLOiwKSS8oyHkWJf2VmdjwwA3gjmm5tZoUvIYlIunz6aRiG9LHHwvTZZ8NllylJSIVJ5S/tFsI9ET8BuPsMwtgUIpJO69eH9of99oM5c2CrreKOSCqpVNoo1rv7z7bpbf/qoiqSTjNmhDuqZ8wIZTceeAB22inuqKSSSiVRzDaz04CqUcmNy4H30xuWSCW3bFl4PP88/OEPcUcjlVwql57+SBgvex3wDKHcuMajEClvEyfCgw+G5127whdfKElIRiix15OZtXH3jyoonhKp15PknJUr4YYbwhgRTZvCJ5+oPpOUu7T2egLuMbO5ZvZXM2tZmp2ISDHGjAlF/B58EK64QkX8JCOVmCjc/UjCyHbfA0PM7BMz+3PaIxPJdYsXQ/fusOWW4bLTvfeqZ5NkpJQ6Yrv7Mne/H7iIcE/F/6U1KpFc5Q5TpoTnjRrB66/D9OkqwSEZLZUb7pqZ2S1m9gnwAKHHU8O0RyaSa775JgxD2q5dQRG/o45SET/JeKl0j30c+A9wjLt/neZ4RHKPOwwbBldfDWvXwp13hjpNIlmixETh7u0rIhCRnNW7N4wcGcaJePRR2GuvuCMS2SzFJgoze9bde0eXnBL70KY6wp1I5bVhQyjgV6UKHH88dOoEF16o+kySlZKdUVwR/exeEYGI5Iy5c+G880IJjgsugLPOijsikTJJNsLdN9HTS4oY3e6SiglPJIusXw8DBkDr1jBvHtStG3dEIuUilfPgLkXMO7a8AxHJatOnhyFJ//IXOOmkcFbRu3fcUYmUi2RtFBcTzhx2N7OZCYvqAO+lOzCRrPLtt/DDDzBqFPToEXc0IuWq2FpPZlYX2Ba4Hbg+YdFKd/+xAmIrkmo9ScaYMCHUZbr00jC9Zg3UqhVvTCLFSFetJ3f3L4FLgZUJD8xsu9LsTCQn/PJLGIa0Y0e4/35Yty7MV5KQHJWs19MzhB5P0wjdYxNHLnJg9zTGJZKZXnstdHP9+utwA91tt6mIn+S8YhOFu3ePfmrYUxEIRfx69IC99w430LVrF3dEIhUilVpPh5hZ7ej5GWY2yMwapz80kQzgDpMmheeNGsGbb4ZS4EoSUomk0j32IWC1me0H9Ae+AJ5Ma1QimeDrr+HEE6F9+4IifkceCdWrxxuXSAVLJVHkeega1QP4p7sPJnSRFclN7qEmU/Pm4Qzi7rtVxE8qtVSqx640sxuAM4HDzKwKUC29YYnEqFcveOGF0Kvp0Udhzz3jjkgkVqmcUZwCrAPOdfdlhLEoBqY1KpGKtmEDbNwYnp94Ijz8MIwdqyQhQpIb7jZZyWxH4MBocoq7f5fWqJLQDXdS7mbNgvPPD4X8Lrgg7mhE0iJdN9zlb7w3MAU4GegNTDazXqXZmUhG+e03uPVWaNMGvvgCtt027ohEMlIqbRQ3AQfmn0WY2fbAW8DIdAYmklbTpkHfvuFs4rTT4N57Yfvt445KJCOlkiiqFLrUtJzU2jZEMtfy5fDTT/Dyy9BdQ66IJJNKonjDzMYAw6PpU4DX0heSSJqMGxeK+F1+ORx9NHz+OdSsGXdUIhmvxDMDd78WGAK0ih5D3f26dAcmUm5+/jnUZ+rUCR56qKCIn5KESEqSjUfRFLgb2AP4BLjG3ZdWVGAi5eLll+Gii2DZMrjmmtB4rSJ+Ipsl2RnF48ArQE9CBdkHKiQikfKyeDH07An16oV6TQMHwpZbxh2VSNZJ1kZRx90fiZ7PM7OPKiIgkTJxhw8+gA4dCor4deig+kwiZZDsjKKmme1vZm3MrA1Qq9B0icysq5nNM7P5ZnZ9kvV6mpmbWaluBhEBYMkSOOGEUJcpv4jfEUcoSYiUUbIzim+AQQnTyxKmHeiUbMNmVhUYDHQBlgAfmtlod59TaL06wBXA5M0LXSSycSM88ghcey3k5cGgQXDooXFHJZIzkg1cdGQZt30QMN/dFwCY2QhCBdo5hdb7K3AncG0Z9yeVVc+eMGpU6NX0yCOwuwZfFClP6bxxrgGwOGF6STTvf6JLWI3c/dVkGzKzfmY21cymbtiQV/6RSvbJyyso4tezZ0gQb72lJCGSBrHdYR2VKx9EGAwpKXcf6u5t3b1t1aqp3CMoOW3mzDCY0CNRX4szzghF/cySv05ESiWdiWIp0ChhumE0L18doCUw3sy+BA4GRqtBW4q1bh3cfDMccAB89ZVqM4lUkFSqx1o0Vvb/RdONzeygFLb9IdDUzJqYWXWgDzA6f6G7/+zu9d19N3ffDZgEnODuqiEuv/fhh6HK6223wamnwty58Ic/xB2VSKWQyhnFg0B74NRoeiWhN1NS7p4HXAaMAeYCz7r7bDO7zcxOKGW8UlmtWAGrVsFrr8G//x1uohORClHiwEVm9pG7tzGz6e6+fzTvY3ffr0IiLEQDF1UiY8eGIn5XXBGm161T+Q2RUkrrwEXA+uieCI92tj2wsTQ7E0nJTz+FkeY6d4YhQwqK+ClJiMQilURxP/AisIOZ/Q2YCPw9rVFJ5fXSS9C8OTz+OPzpT2GAISUIkViV2NfU3Z82s2lAZ8CAE919btojk8pn0SI4+WRo1gxGj4a26gAnkglKTBRm1hhYDbycOM/dF6UzMKkk3GHiRDjsMGjcONw0d/DBqs8kkkFSuXvtVUL7hAE1gSbAPKBFGuOSymDRojBWxOuvw/jx0LEjHH543FGJSCGpXHraN3E6KrtxSdoikty3cSM8/DBcd104o7j/fhXxE8lgm10Pw90/MrN26QhGKok//CE0WnfpAkOHwm67xR2RiCSRShvF1QmTVYA2wNdpi0hyU14eVKkSHqecAj16QN++qs8kkgVS6R5bJ+FRg9Bm0SOdQUmO+fhjaNcunD1AKMFxzjlKEiJZIukZRXSjXR13v6aC4pFcsnYtDBgAd94J220HO+0Ud0QiUgrFJgoz28Ld88zskIoMSHLElClw9tnw6afh56BBIVmISNZJdkYxhdAeMcPMRgPPAb/mL3T3F9Icm2SzX36BNWvgjTfgmGPijkZEyiCVXk81geWEMbLz76dwQIlCNvXmmzB7Nlx1FRx1FMybp/IbIjkgWaLYIerxNIuCBJEveclZqVxWrICrr4Zhw6BFC7jkkpAglCREckKyXk9Vga2iR52E5/kPEXjhhVDE78kn4cY0vXwAABMWSURBVIYbYOpUJQiRHJPsjOIbd7+twiKR7LNoEfTpAy1bhgGF9t8/7ohEJA2SnVGok7v8nju880543rhxGFxo8mQlCZEclixRdK6wKCQ7fPUVHHssHHFEQbI49FCoVi3WsEQkvYpNFO7+Y0UGIhls40b45z9DQ/XEifDAA6EsuIhUCptdFFAqoRNPhJdfDvdDDBkCu+4ad0QiUoGUKKRo69dD1aqhiN+pp0KvXnDmmarPJFIJpVIUUCqbjz6Cgw4KY0ZASBRnnaUkIVJJKVFIgTVrwr0QBx0Ey5ZBo0ZxRyQiGUCXniSYNCkU7/vsMzj3XLj7bth227ijEpEMoEQhwa+/hnaJ//431GkSEYkoUVRmb7wRivj17w+dO4eS4NWrxx2ViGQYtVFURsuXh8tMxx4LTzwBv/0W5itJiEgRlCgqE3cYOTIU8XvmGfjzn+HDD5UgRCQpXXqqTBYtgtNOg1atwtgR++0Xd0QikgV0RpHr3EPhPgh3VI8fH3o4KUmISIqUKHLZwoVw9NGhoTq/iF+HDrCFTiRFJHVKFLlowwa4774wTsTkyfDQQyriJyKlpq+WuahHD3j1VejWLZTh0B3WIlIGShS5IrGI35lnhvpMp52m+kwiUmZpvfRkZl3NbJ6ZzTez64tYfrWZzTGzmWb2tpmpfnVpTJ0KbduGS0wAp5wCp5+uJCEi5SJticLMqgKDgWOB5sCpZta80GrTgbbu3goYCdyVrnhy0po1cN110K4dfP+9xokQkbRI5xnFQcB8d1/g7r8BI4AeiSu4+zh3Xx1NTgIapjGe3PLBB6GL6113hSJ+c+ZA9+5xRyUiOSidbRQNgMUJ00uAdknWPw94vagFZtYP6AdQrZr6/wPhbGLjRnjrrdD9VUQkTTKiMdvMzgDaAh2LWu7uQ4GhALVqtfUKDC2zvPZaKOJ37bXQqRPMnQvVqsUdlYjkuHReeloKJPbLbBjN24SZHQXcBJzg7uvSGE/2+uEHOOMMOO44ePrpgiJ+ShIiUgHSmSg+BJqaWRMzqw70AUYnrmBm+wNDCEniuzTGkp3cYcQIaNYMnn0Wbr4ZpkxRET8RqVBpu/Tk7nlmdhkwBqgKPO7us83sNmCqu48GBgJbAc9Z6Mq5yN1PSFdMWWfRolAOfL/94LHHYN99445IRCohc8+uS/61arX1NWumxh1G+rjD228XjDI3aRIceGC4mU5EpJTMbJq7ty3Na1XrKZN88UXowdSlS0ERv4MPVpIQkVgpUWSCDRtg0KBwaWnaNBgyREX8RCRjZET32Erv+OPh9dfDDXMPPQQNdd+hiGQOJYq4/PZbGBeiShXo2zcU8uvTR/WZRCTj6NJTHKZMgQMOgAcfDNO9e4dqr0oSIpKBlCgq0urV0L8/tG8PK1bAHnvEHZGISIl06amiTJwY7olYsAAuvBDuvBPq1o07KhGREilRVJT8gYXGjYMjjog7GhGRlClRpNPLL4fCfX/6Exx5ZCgFvoUOuYhkF7VRpMP334dhSE84AYYPLyjipyQhIllIiaI8ucMzz4QifiNHwm23weTJKuInIllNX3HL06JFcM45sP/+oYhfixZxRyQiUmY6oyirjRthzJjwfNdd4d134b33lCREJGcoUZTF55+Hkea6doUJE8K8gw5SET8RySlKFKWRlwcDB0KrVjBjRrjMpCJ+IpKj1EZRGt27h8tNPXqEMhy77BJ3RCIZaf369SxZsoS1a9fGHUqlUbNmTRo2bEi1chwqWQMXpWrdujBGdZUqoUfTxo1w8smqzySSxMKFC6lTpw716tXD9L+Sdu7O8uXLWblyJU2aNNlkmQYuSrdJk6BNGxg8OEz36hUK+ekPXySptWvXKklUIDOjXr165X4Gp0SRzK+/wlVXQYcOsHIlNG0ad0QiWUdJomKl43irjaI4774bivgtXAiXXAK33w5bbx13VCIiFU5nFMXJywttEu+8Ey45KUmIZK1Ro0ZhZnz66af/mzd+/Hi6d+++yXp9+/Zl5MiRQGiIv/7662natClt2rShffv2vP7662WO5fbbb2fPPfdk7733Zkz+PViFjB07ljZt2tCyZUvOPvts8vLyAPj0009p3749NWrU4O677y5zLKlSokg0alQ4c4BQxG/2bDj88HhjEpEyGz58OIceeijDhw9P+TV/+ctf+Oabb5g1axYfffQRo0aNYuXKlWWKY86cOYwYMYLZs2fzxhtvcMkll7Bhw4ZN1tm4cSNnn302I0aMYNasWey666488cQTAGy33Xbcf//9XHPNNWWKY3Pp0hPAt9/CH/8Izz0XGq379w/1mVTET6TcXHlluO2oPLVuDffem3ydVatWMXHiRMaNG8fxxx/PrbfeWuJ2V69ezSOPPMLChQupUaMGADvuuCO9e/cuU7wvvfQSffr0oUaNGjRp0oQ999yTKVOm0L59+/+ts3z5cqpXr85ee+0FQJcuXbj99ts577zz2GGHHdhhhx149dVXyxTH5qrcZxTu8OST0Lw5vPQS/O1voYeTiviJ5IyXXnqJrl27stdee1GvXj2mTZtW4mvmz59P48aN2TqFS85XXXUVrVu3/t3jjjvu+N26S5cupVGjRv+bbtiwIUuXLt1knfr165OXl8fUqeE2gJEjR7J48eIS40inyv2VedEiOP98aNs23F29zz5xRySSs0r65p8uw4cP54orrgCgT58+DB8+nAMOOKDY3kGb22voH//4R5ljLLz/ESNGcNVVV7Fu3TqOPvpoqsZcFqjyJYr8In7HHhuK+L33Xqj2qvpMIjnnxx9/ZOzYsXzyySeYGRs2bMDMGDhwIPXq1WPFihW/W79+/frsueeeLFq0iF9++aXEs4qrrrqKcePG/W5+nz59uP766zeZ16BBg03ODpYsWUKDBg1+99r27dvz7rvvAvDmm2/y2Wefpfye08Lds+pRs+YBXmrz5rkfdpg7uI8fX/rtiEhK5syZE+v+hwwZ4v369dtk3uGHH+7vvPOOr1271nfbbbf/xfjll19648aN/aeffnJ392uvvdb79u3r69atc3f37777zp999tkyxTNr1ixv1aqVr1271hcsWOBNmjTxvLy836337bffurv72rVrvVOnTv72229vsvzmm2/2gQMHFrufoo47MNVL+blbOdoo8vLgzjtDEb9PPoF//Uu9mUQqgeHDh3PSSSdtMq9nz54MHz6cGjVq8NRTT3HOOefQunVrevXqxaOPPkrdunUBGDBgANtvvz3NmzenZcuWdO/ePaU2i2RatGhB7969ad68OV27dmXw4MH/u6zUrVs3vv76awAGDhxIs2bNaNWqFccffzydOnUCYNmyZTRs2JBBgwYxYMAAGjZsyC+//FKmmFJROWo9HXMMvPkm/OEP4Z6InXZKT3Aisom5c+fSrFmzuMOodIo67mWp9ZS7bRRr14Yb5qpWhX79wqNnz7ijEhHJOrl56em990IH6/wifj17KkmIiJRSbiWKVavg8svDIEJr14JOeUVil22Xt7NdOo537iSKd96Bli3hn/+Eyy6DWbOgS5e4oxKp1GrWrMny5cuVLCqIR+NR1KxZs1y3m1ttFFtuGaq+HnJI3JGICOHO4yVLlvD999/HHUqlkT/CXXnK7l5PL7wAn34KN94Ypjds0I1zIiJFyNgR7sysq5nNM7P5ZnZ9EctrmNl/ouWTzWy3lDa8bFkYZa5nT3jxRfjttzBfSUJEpNylLVGYWVVgMHAs0Bw41cyaF1rtPGCFu+8J/AO4s6TtbrNheWikfuWVUBL8/fdVxE9EJI3SeUZxEDDf3Re4+2/ACKBHoXV6AE9Ez0cCna2Eily7rP8qNFp//DFcf324V0JERNImnY3ZDYDE2rhLgHbFrePueWb2M1AP+CFxJTPrB/SLJtfZxImzVOkVgPoUOlaVmI5FAR2LAjoWBfYu7QuzoteTuw8FhgKY2dTSNsjkGh2LAjoWBXQsCuhYFDCzzax9VCCdl56WAo0SphtG84pcx8y2AOoCy9MYk4iIbKZ0JooPgaZm1sTMqgN9gNGF1hkNnB097wWM9WzrrysikuPSdukpanO4DBgDVAUed/fZZnYboS76aOAx4Ekzmw/8SEgmJRmarpizkI5FAR2LAjoWBXQsCpT6WGTdDXciIlKxcqfWk4iIpIUShYiIJJWxiSJt5T+yUArH4mozm2NmM83sbTPbNY44K0JJxyJhvZ5m5maWs10jUzkWZtY7+tuYbWbPVHSMFSWF/5HGZjbOzKZH/yfd4ogz3czscTP7zsxmFbPczOz+6DjNNLM2KW24tINtp/NBaPz+AtgdqA58DDQvtM4lwMPR8z7Af+KOO8ZjcSSwZfT84sp8LKL16gATgElA27jjjvHvoikwHdg2mt4h7rhjPBZDgYuj582BL+OOO03H4nCgDTCrmOXdgNcBAw4GJqey3Uw9o0hL+Y8sVeKxcPdx7r46mpxEuGclF6XydwHwV0LdsLUVGVwFS+VYXAAMdvcVAO7+XQXHWFFSORYObB09rwt8XYHxVRh3n0DoQVqcHsC/PZgEbGNmO5e03UxNFEWV/2hQ3Drungfkl//INakci0TnEb4x5KISj0V0Kt3I3V+tyMBikMrfxV7AXmb2nplNMrOuFRZdxUrlWNwCnGFmS4DXgD9WTGgZZ3M/T4AsKeEhqTGzM4C2QMe4Y4mDmVUBBgF9Yw4lU2xBuPx0BOEsc4KZ7evuP8UaVTxOBYa5+z1m1p5w/1ZLd98Yd2DZIFPPKFT+o0AqxwIzOwq4CTjB3ddVUGwVraRjUQdoCYw3sy8J12BH52iDdip/F0uA0e6+3t0XAp8REkeuSeVYnAc8C+DuHwA1CQUDK5uUPk8Ky9REofIfBUo8Fma2PzCEkCRy9To0lHAs3P1nd6/v7ru5+26E9poT3L3UxdAyWCr/I6MIZxOYWX3CpagFFRlkBUnlWCwCOgOYWTNCoqiM47OOBs6Kej8dDPzs7t+U9KKMvPTk6Sv/kXVSPBYDga2A56L2/EXufkJsQadJiseiUkjxWIwBjjazOcAG4Fp3z7mz7hSPRX/gETO7itCw3TcXv1ia2XDCl4P6UXvMzUA1AHd/mNA+0w2YD6wGzklpuzl4rEREpBxl6qUnERHJEEoUIiKSlBKFiIgkpUQhIiJJKVGIiEhSShSSkcxsg5nNSHjslmTdVeWwv2FmtjDa10fR3bubu41Hzax59PzGQsveL2uM0Xbyj8ssM3vZzLYpYf3WuVopVSqOusdKRjKzVe6+VXmvm2Qbw4BX3H2kmR0N3O3urcqwvTLHVNJ2zewJ4DN3/1uS9fsSKuheVt6xSOWhMwrJCma2VTTWxkdm9omZ/a5qrJntbGYTEr5xHxbNP9rMPohe+5yZlfQBPgHYM3rt1dG2ZpnZldG82mb2qpl9HM0/JZo/3szamtkdQK0ojqejZauinyPM7LiEmIeZWS8zq2pmA83sw2icgAtTOCwfEBV0M7ODovc43czeN7O9o7uUbwNOiWI5JYr9cTObEq1bVPVdkU3FXT9dDz2KehDuJJ4RPV4kVBHYOlpWn3Bnaf4Z8aroZ3/gpuh5VULtp/qED/7a0fzrgP8rYn/DgF7R85OBycABwCdAbcKd77OB/YGewCMJr60b/RxPNP5FfkwJ6+THeBLwRPS8OqGSZy2gH/DnaH4NYCrQpIg4VyW8v+eArtH01sAW0fOjgOej532Bfya8/u/AGdHzbQj1n2rH/fvWI7MfGVnCQwRY4+6t8yfMrBrwdzM7HNhI+Ca9I7As4TUfAo9H645y9xlm1pEwUM17UXmT6oRv4kUZaGZ/JtQAOo9QG+hFd/81iuEF4DDgDeAeM7uTcLnq3c14X68D95lZDaArMMHd10SXu1qZWa9ovbqEAn4LC72+lpnNiN7/XOC/Ces/YWZNCSUqqhWz/6OBE8zsmmi6JtA42pZIkZQoJFucDmwPHODu6y1Uh62ZuIK7T4gSyXHAMDMbBKwA/uvup6awj2vdfWT+hJl1Lmold//MwrgX3YABZva2u9+Wyptw97VmNh44BjiFMMgOhBHH/ujuY0rYxBp3b21mWxJqG10K3E8YrGmcu58UNfyPL+b1BvR093mpxCsCaqOQ7FEX+C5KEkcCvxsX3MJY4d+6+yPAo4QhIScBh5hZfptDbTPbK8V9vgucaGZbmlltwmWjd81sF2C1uz9FKMhY1LjD66Mzm6L8h1CMLf/sBMKH/sX5rzGzvaJ9FsnDiIaXA/2toMx+frnovgmrriRcgss3BvijRadXFioPiySlRCHZ4mmgrZl9ApwFfFrEOkcAH5vZdMK39fvc/XvCB+dwM5tJuOy0Tyo7dPePCG0XUwhtFo+6+3RgX2BKdAnoZmBAES8fCszMb8wu5E3C4FJveRi6E0JimwN8ZGazCGXjk57xR7HMJAzKcxdwe/TeE183Dmie35hNOPOoFsU2O5oWSUrdY0VEJCmdUYiISFJKFCIikpQShYiIJKVEISIiSSlRiIhIUkoUIiKSlBKFiIgk9f+30mLRfkkVjwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute predicted probabilities on the test set\n",
    "probs = bert_predict(classifier, val_dataloader)\n",
    "\n",
    "# Evaluate the Bert classifier\n",
    "evaluate_roc(probs, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 features without ratio works better than 5 features with TFF\n",
    "6 features with addition of creation time is better than 5 features AUC=84.4,\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        fake       0.82      0.70      0.76        20\n",
    "        real       0.79      0.88      0.83        25\n",
    "        \n",
    "        \n",
    "best perforimg features so far are TFF,fav_count, tweet_count and age of the created account.  AUC=94% and accuracy:84.4%\n",
    " precision    recall  f1-score   support\n",
    "\n",
    "        fake       0.88      0.75      0.81        20\n",
    "        real       0.82      0.92      0.87        25\n",
    "        micro avg       0.84      0.84      0.84        45\n",
    "        macro avg       0.85      0.83      0.84        45\n",
    "        weighted avg       0.85      0.84      0.84        45\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
